{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install wandb\n",
    "#!pip install tf-models-official==2.10\n",
    "#!pip install numpy\n",
    "#!pip install nibabel\n",
    "#!pip install matplotlib\n",
    "#!pip install scikit-image\n",
    "#!pip install scikit-learn\n",
    "#!pip install keras\n",
    "#!pip install tensorflow==2.10\n",
    "#!pip install opencv-python\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage \n",
    "from skimage.transform import rotate\n",
    "import keras\n",
    "import random\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import cv2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unpack data** \n",
    "\n",
    "*NB: Size is 13.5 GB, code is commented out to prevent accidental unpacking*\n",
    "\n",
    "**TEST THIS BEFORE HAND IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data can be downloaded here: https://www.kaggle.com/datasets/dschettler8845/brats-2021-task1\n",
    "# Make sure the file is in the same folder as this project\n",
    "\n",
    "#import tarfile\n",
    "#file = tarfile.open('./BraTS2021_Training_Data.tar')\n",
    "\n",
    "#file.extractall(os.getenv('TRAIN-PATH'))\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from: https://www.kaggle.com/code/malik12345/brain-tumor-detection-using-cnn-model\n",
    "\n",
    "axis = (0,1,2,3)\n",
    "\n",
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_healthy(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,0] * y_pred[0,:,:,:,0]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,0])) + K.sum(K.square(y_pred[0,:,:,:,0])) + epsilon)\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,1] * y_pred[0,:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,1])) + K.sum(K.square(y_pred[0,:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,2] * y_pred[0,:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,2])) + K.sum(K.square(y_pred[0,:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,3] * y_pred[0,:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,3])) + K.sum(K.square(y_pred[0,:,:,:,3])) + epsilon)\n",
    "\n",
    " \n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=axis)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=axis)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=axis)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=axis)\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)), axis=axis)\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)), axis=axis)\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=120 # Originally 240x240, we reduce this to reduce memory usage\n",
    "SLICES=128 # Originally 155, reduced for same reason. Must be a power of 2 (or at least divisible by 2, 3 times)\n",
    "SLICES_START=13 # We skip the first (and the last) few slices as they should contain less information\n",
    "BATCH_SIZE=1\n",
    "CHANNELS=4\n",
    "DATA_AUG=False # Enables data augmentation\n",
    "DATA_AUG_FACTOR=0 # If we have n data elements, we will have DATA_AUG_FACTOR*n data elements to train on\n",
    "\n",
    "TRAIN_DATASET_PATH = os.getenv('TRAIN-PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomBrightness(X, y):\n",
    "  X = tf.image.stateless_random_brightness(X, 0.2, seed=(1,2)).numpy()\n",
    "  y = tf.image.stateless_random_brightness(y, 0.2, seed=(1,2)).numpy()\n",
    "  return X, y\n",
    "\n",
    "def RandomRotate(X, y):\n",
    "    r = random.randint(0,3)\n",
    "    # rotate by 90 degrees times random r\n",
    "    X = np.rot90(X, k=r)\n",
    "    y = np.rot90(y, k=r)\n",
    "    return X, y \n",
    "    \n",
    "def AugmentData(X, y):\n",
    "  X, y = RandomRotate(X, y)\n",
    "  X, y = RandomBrightness(X, y)\n",
    "  return X, y\n",
    "\n",
    "# Some of the data generation was borrowed from: https://www.kaggle.com/code/malik12345/brain-tumor-detection-using-cnn-model\n",
    "  \n",
    "data_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "data_ids = pathListIntoIds(data_directories); \n",
    "\n",
    "    \n",
    "train_and_test_ids, val_ids = train_test_split(data_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(train_and_test_ids,test_size=0.2)\n",
    "\n",
    "\n",
    "keras = tf.compat.v1.keras\n",
    "Sequence = keras.utils.Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = BATCH_SIZE, n_channels = CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*SLICES, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');\n",
    "            ce = nib.load(data_path).get_fdata()   \n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1.nii.gz');\n",
    "            t1 = nib.load(data_path).get_fdata()       \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii.gz');\n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(SLICES):\n",
    "                X[j+(SLICES*c),:,:,0] = cv2.resize(flair[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,1] = cv2.resize(ce[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,2] = cv2.resize(t1[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,3] = cv2.resize(t2[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))                \n",
    "                \n",
    "                y[j +SLICES*c,:,:] = cv2.resize(seg[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        if DATA_AUG: X, y = AugmentData(X, y)\n",
    "\n",
    "        X = X.reshape(1,SLICES,IMG_SIZE,IMG_SIZE, CHANNELS)\n",
    "        y = y.reshape(1,SLICES,IMG_SIZE,IMG_SIZE)\n",
    "        # Generate masks\n",
    "        y = tf.one_hot(y, 4);\n",
    "\n",
    "        # Avoid dividing by zero - return early\n",
    "        if np.max(X) == 0.0:\n",
    "          return np.zeros(X.shape), y\n",
    "\n",
    "        return X/np.max(X), y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids*DATA_AUG_FACTOR) if DATA_AUG else DataGenerator(train_ids) \n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c2)\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = UpSampling3D(2)(c11)\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = UpSampling3D(2)(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = UpSampling3D(2)(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "model = unet_3d(input_layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test (baseline) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 120, 1  0           []                               \n",
      "                                20, 4)]                                                           \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 128, 120, 12  872         ['input_1[0][0]']                \n",
      "                                0, 8)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 120, 12  32         ['conv3d[0][0]']                 \n",
      " alization)                     0, 8)                                                             \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 128, 120, 12  0           ['batch_normalization[0][0]']    \n",
      "                                0, 8)                                                             \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 128, 120, 12  3472        ['activation[0][0]']             \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 120, 12  64         ['conv3d_1[0][0]']               \n",
      " rmalization)                   0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128, 120, 12  0           ['batch_normalization_1[0][0]']  \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 64, 60, 60,   0           ['activation_1[0][0]']           \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 64, 60, 60,   6928        ['max_pooling3d[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 60, 60,   64         ['conv3d_2[0][0]']               \n",
      " rmalization)                   16)                                                               \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 64, 60, 60,   0           ['batch_normalization_2[0][0]']  \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 64, 60, 60,   13856       ['activation_2[0][0]']           \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 60, 60,   128        ['conv3d_3[0][0]']               \n",
      " rmalization)                   32)                                                               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 64, 60, 60,   0           ['batch_normalization_3[0][0]']  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPooling3D)  (None, 32, 30, 30,   0          ['activation_3[0][0]']           \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 32, 30, 30,   27680       ['max_pooling3d_1[0][0]']        \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 30, 30,   128        ['conv3d_4[0][0]']               \n",
      " rmalization)                   32)                                                               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 30, 30,   0           ['batch_normalization_4[0][0]']  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 32, 30, 30,   55360       ['activation_4[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 30, 30,   256        ['conv3d_5[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 30, 30,   0           ['batch_normalization_5[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPooling3D)  (None, 16, 15, 15,   0          ['activation_5[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 16, 15, 15,   110656      ['max_pooling3d_2[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 15, 15,   256        ['conv3d_6[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 15, 15,   0           ['batch_normalization_6[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 16, 15, 15,   221312      ['activation_6[0][0]']           \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 15, 15,   512        ['conv3d_7[0][0]']               \n",
      " rmalization)                   128)                                                              \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 15, 15,   0           ['batch_normalization_7[0][0]']  \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " up_sampling3d (UpSampling3D)   (None, 32, 30, 30,   0           ['activation_7[0][0]']           \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 30, 30,   0           ['activation_5[0][0]',           \n",
      "                                192)                              'up_sampling3d[0][0]']          \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 32, 30, 30,   331840      ['concatenate[0][0]']            \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32, 30, 30,   256        ['conv3d_8[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 32, 30, 30,   0           ['batch_normalization_8[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 32, 30, 30,   110656      ['activation_8[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 32, 30, 30,   256        ['conv3d_9[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 32, 30, 30,   0           ['batch_normalization_9[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " up_sampling3d_1 (UpSampling3D)  (None, 64, 60, 60,   0          ['activation_9[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 60, 60,   0           ['activation_3[0][0]',           \n",
      "                                96)                               'up_sampling3d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)             (None, 64, 60, 60,   82976       ['concatenate_1[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 64, 60, 60,   128        ['conv3d_10[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_10[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)             (None, 64, 60, 60,   27680       ['activation_10[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 64, 60, 60,   128        ['conv3d_11[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_11[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " up_sampling3d_2 (UpSampling3D)  (None, 128, 120, 12  0          ['activation_11[0][0]']          \n",
      "                                0, 32)                                                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 120, 12  0           ['activation_1[0][0]',           \n",
      "                                0, 48)                            'up_sampling3d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)             (None, 128, 120, 12  20752       ['concatenate_2[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 128, 120, 12  64         ['conv3d_12[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_12[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)             (None, 128, 120, 12  6928        ['activation_12[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 128, 120, 12  64         ['conv3d_13[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_13[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)             (None, 128, 120, 12  68          ['activation_13[0][0]']          \n",
      "                                0, 4)                                                             \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 128, 120, 12  0           ['conv3d_14[0][0]']              \n",
      "                                0, 4)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,023,372\n",
      "Trainable params: 1,022,204\n",
      "Non-trainable params: 1,168\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "599/800 [=====================>........] - ETA: 1:44 - loss: 0.2545 - accuracy: 0.9532 - mean_io_u: 0.3753 - dice_coef: 0.9326 - precision: 0.9414 - sensitivity: 0.9116 - specificity: 0.9935 - dice_coef_necrotic: 0.1592 - dice_coef_edema: 0.3240 - dice_coef_enhancing: 0.0508 - dice_coef_healthy: 0.9484"
     ]
    }
   ],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = False # Whether to save the model after training\n",
    "\n",
    "# wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "# wandb.config = {\n",
    "#   \"learning_rate\": LR,\n",
    "#   \"epochs\": EPOCHS,\n",
    "#   \"batch_size\": BATCH_SIZE,\n",
    "#   \"img_size\": IMG_SIZE, \n",
    "#   \"slices\": SLICES\n",
    "# }\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=LR), loss=\"categorical_crossentropy\", metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "model.summary()\n",
    "model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[])\n",
    "if SAVE_MODEL:\n",
    "  model.save(\"baseline_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruct model and test it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"baseline_model.h5\", custom_objects={\"dice_coef\":dice_coef, \n",
    "                                                                                \"precision\":precision, \n",
    "                                                                                \"sensitivity\":sensitivity, \n",
    "                                                                                \"specificity\":specificity,\n",
    "                                                                                \"dice_coef_necrotic\":dice_coef_necrotic, \n",
    "                                                                                \"dice_coef_edema\":dice_coef_edema, \n",
    "                                                                                \"dice_coef_enhancing\":dice_coef_enhancing,\n",
    "                                                                                \"dice_coef_healthy\": dice_coef_healthy})\n",
    "reconstructed_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Callbacks for improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_dice_coef', min_delta=0,\n",
    "                               patience=5, verbose=1, mode='max'),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_dice_coef', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1, mode='max')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = Conv3D(16, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c2) # Use convolution instead of max pool\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = Conv3D(32, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = Conv3DTranspose(128, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c11) # Use Transpose instead of UpSampling, kernel size should be divisble by stride\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = Conv3DTranspose(64, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = Conv3DTranspose(32, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "improved_model = unet_3d(input_layer) \n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = True # Whether to save the model after training\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "improved_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=LR), loss=\"categorical_crossentropy\", metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "improved_model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[callbacks, WandbCallback()])\n",
    "if SAVE_MODEL: improved_model.save(\"improved_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruct saved model and evaluate it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"improved_model.h5\", custom_objects={\"dice_coef\":dice_coef, \n",
    "                                                                                \"precision\":precision, \n",
    "                                                                                \"sensitivity\":sensitivity, \n",
    "                                                                                \"specificity\":specificity,\n",
    "                                                                                \"dice_coef_necrotic\":dice_coef_necrotic, \n",
    "                                                                                \"dice_coef_edema\":dice_coef_edema, \n",
    "                                                                                \"dice_coef_enhancing\":dice_coef_enhancing,\n",
    "                                                                                \"dice_coef_healthy\": dice_coef_healthy})\n",
    "reconstructed_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 0 is just an index of a 3D scan\n",
    "# Next 0 is X in tuple X, y\n",
    "# Next 0 is from the batch. We only have one, so we pick the first.\n",
    "img1 = training_generator.__getitem__(0)[0][0]\n",
    "\n",
    "# Get the ground truth of the training image above (i.e. y from tuple (X, y))\n",
    "img2 = training_generator.__getitem__(0)[1][0]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "# [70,:,:,0] is slice 70. 0 is the FLAIR channel.\n",
    "plt.imshow(img1[70,:,:,0])\n",
    "plt.show()\n",
    "\n",
    "# Same slice as above, 1 is the necrotic tumor core\n",
    "plt.imshow(img2[70, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions? Maybe we should do an example (or a few) where we use the trained model to predict segmentation masks on data we have not trained on (i.e. the two brain scans that were included in the data set but not in the training-data file**\n",
    "\n",
    "**Something like this:** https://www.kaggle.com/code/watermasterz/mri-brats-3d-conv **(scroll down a bit)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4270e3f338dc97884e39dfa435881d633bb85d0979a79226f74580c90b39f6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
