{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage \n",
    "from skimage.transform import rotate\n",
    "import keras\n",
    "import random\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import cv2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unpack data** \n",
    "\n",
    "*NB: Size is 13.5 GB, code is commented out to prevent accidental unpacking*\n",
    "\n",
    "**TEST THIS BEFORE HAND IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tarfile\n",
    "#file = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')\n",
    "\n",
    "#file.extractall(os.getenv('TRAIN-PATH'))\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics and loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "        =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    axis = (0,1,2,3)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "# Loss functions here: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook\n",
    "\n",
    "ALPHA = 0.7\n",
    "BETA = 0.3\n",
    "GAMMA = 1\n",
    "\n",
    "def focal_tversky_loss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):\n",
    "    \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))\n",
    "               \n",
    "        Tversky = (TP + smooth) / (TP + beta*FP + alpha*FN + smooth)  \n",
    "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
    "        \n",
    "        return FocalTversky\n",
    "\n",
    "\n",
    "\n",
    "# define per class evaluation of dice coef\n",
    "# inspired by https://github.com/keras-team/keras/issues/9395\n",
    "def dice_coef_healthy(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,0] * y_pred[0,:,:,:,0]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,0])) + K.sum(K.square(y_pred[0,:,:,:,0])) + epsilon)\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,1] * y_pred[0,:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,1])) + K.sum(K.square(y_pred[0,:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,2] * y_pred[0,:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,2])) + K.sum(K.square(y_pred[0,:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,3] * y_pred[0,:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,3])) + K.sum(K.square(y_pred[0,:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=120 # Originally 240x240, we reduce this to reduce memory usage\n",
    "SLICES=128 # Originally 155, reduced for same reason. Must be a power of 2 (or at least divisible by 2, 3 times)\n",
    "SLICES_START=13 # We skip the first (and the last) few slices as they should contain less information\n",
    "BATCH_SIZE=1\n",
    "CHANNELS=4\n",
    "DATA_AUG=False # Enables data augmentation\n",
    "DATA_AUG_FACTOR=0 # If we have n data elements, we will have DATA_AUG_FACTOR*n data elements to train on\n",
    "\n",
    "TRAIN_DATASET_PATH = os.getenv('TRAIN-PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomBrightness(X, y):\n",
    "  X = tf.image.stateless_random_brightness(X, 0.2, seed=(1,2)).numpy()\n",
    "  y = tf.image.stateless_random_brightness(y, 0.2, seed=(1,2)).numpy()\n",
    "  return X, y\n",
    "\n",
    "def RandomRotate(X, y):\n",
    "    r = random.randint(0,3)\n",
    "    # rotate by 90 degrees times random r\n",
    "    X = np.rot90(X, k=r)\n",
    "    y = np.rot90(y, k=r)\n",
    "    return X, y \n",
    "    \n",
    "def AugmentData(X, y):\n",
    "  X, y = RandomRotate(X, y)\n",
    "  X, y = RandomBrightness(X, y)\n",
    "  return X, y\n",
    "  \n",
    "data_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "data_ids = pathListIntoIds(data_directories); \n",
    "\n",
    "    \n",
    "train_and_test_ids, val_ids = train_test_split(data_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(train_and_test_ids,test_size=0.2)\n",
    "\n",
    "\n",
    "keras = tf.compat.v1.keras\n",
    "Sequence = keras.utils.Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = BATCH_SIZE, n_channels = CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*SLICES, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');\n",
    "            ce = nib.load(data_path).get_fdata()   \n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1.nii.gz');\n",
    "            t1 = nib.load(data_path).get_fdata()       \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii.gz');\n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(SLICES):\n",
    "                X[j+(SLICES*c),:,:,0] = cv2.resize(flair[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,1] = cv2.resize(ce[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,2] = cv2.resize(t1[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,3] = cv2.resize(t2[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))                \n",
    "                \n",
    "                y[j +SLICES*c,:,:] = cv2.resize(seg[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        if DATA_AUG: X, y = AugmentData(X, y)\n",
    "\n",
    "        X = X.reshape(1,SLICES,IMG_SIZE,IMG_SIZE, CHANNELS)\n",
    "        y = y.reshape(1,SLICES,IMG_SIZE,IMG_SIZE)\n",
    "        # Generate masks\n",
    "        #y[y==4] = 3;\n",
    "        y = tf.one_hot(y, 4);\n",
    "\n",
    "        # Avoid dividing by zero - return early\n",
    "        if np.max(X) == 0.0:\n",
    "          return np.zeros(X.shape), y\n",
    "\n",
    "        return X/np.max(X), y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids*DATA_AUG_FACTOR) if DATA_AUG else DataGenerator(train_ids) \n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c2)\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = UpSampling3D(2)(c11)\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = UpSampling3D(2)(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = UpSampling3D(2)(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "model = unet_3d(input_layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test (baseline) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = False # Whether to save the model after training\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=LR), loss=\"categorical_crossentropy\", metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "model.summary()\n",
    "model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[WandbCallback()])\n",
    "if SAVE_MODEL:\n",
    "  model.save(\"baseline_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruct model and test it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"baseline_model.h5\", custom_objects={\"dice_coef\":dice_coef, \n",
    "                                                                                \"precision\":precision, \n",
    "                                                                                \"sensitivity\":sensitivity, \n",
    "                                                                                \"specificity\":specificity,\n",
    "                                                                                \"dice_coef_necrotic\":dice_coef_necrotic, \n",
    "                                                                                \"dice_coef_edema\":dice_coef_edema, \n",
    "                                                                                \"dice_coef_enhancing\":dice_coef_enhancing,\n",
    "                                                                                \"dice_coef_healthy\": dice_coef_healthy})\n",
    "reconstructed_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Callbacks for improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,\n",
    "                               patience=2, verbose=1, mode='auto'),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = Conv3D(16, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c2) # Use convolution instead of max pool\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = Conv3D(32, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = Conv3DTranspose(128, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c11) # Use Transpose instead of UpSampling, kernel size should be divisble by stride\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = Conv3DTranspose(64, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = Conv3DTranspose(32, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "improved_model = unet_3d(input_layer) \n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = False # Whether to save the model after training\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "improved_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=LR), loss=focal_tversky_loss, metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "improved_model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[callbacks, WandbCallback()])\n",
    "if SAVE_MODEL:\n",
    "  improved_model.save(\"improved_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 0 is just an index of a 3D scan\n",
    "# Next 0 is X in tuple X, y\n",
    "# Next 0 is from the batch. We only have one, so we pick the first.\n",
    "img1 = training_generator.__getitem__(0)[0][0]\n",
    "\n",
    "# Get the ground truth of the training image above (i.e. y from tuple (X, y))\n",
    "img2 = training_generator.__getitem__(0)[1][0]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "# [70,:,:,0] is slice 70. 0 is the FLAIR channel.\n",
    "plt.imshow(img1[70,:,:,0])\n",
    "plt.show()\n",
    "\n",
    "# Same slice as above, 1 is the necrotic tumor core\n",
    "plt.imshow(img2[70, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions? Maybe we should do an example (or a few) where we use the trained model to predict segmentation masks on data we have not trained on (i.e. the two brain scans that were included in the data set but not in the training-data file**\n",
    "\n",
    "**Something like this:** https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/ **(scroll down to \"predictions\")**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4270e3f338dc97884e39dfa435881d633bb85d0979a79226f74580c90b39f6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
