{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 19:11:22.040276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 19:11:22.337154: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-30 19:11:23.058849: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/viktorsalling/miniconda3/lib/\n",
      "2022-11-30 19:11:23.059596: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/viktorsalling/miniconda3/lib/\n",
      "2022-11-30 19:11:23.059603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tarfile\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage \n",
    "from skimage.transform import rotate\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "#from tensorflow.keras.layers.experimental import preprocessing\n",
    "import cv2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unpack data** \n",
    "\n",
    "*NB: Size is 13.5 GB, code is commented out to prevent accidental unpacking*\n",
    "\n",
    "**TEST THIS BEFORE HAND IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')\n",
    "\n",
    "#file.extractall(os.getenv('TRAIN-PATH'))\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics and loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "        =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    axis = (0,1,2,3)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "# Loss functions here: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook\n",
    "\n",
    "ALPHA = 0.8\n",
    "GAMMA = 2\n",
    "\n",
    "def focal_loss(targets, inputs, alpha=ALPHA, gamma=GAMMA):    \n",
    "    \n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    \n",
    "    BCE = K.binary_crossentropy(targets, inputs)\n",
    "    BCE_EXP = K.exp(-BCE)\n",
    "    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)\n",
    "    \n",
    "    return focal_loss\n",
    "\n",
    "\n",
    "\n",
    "# define per class evaluation of dice coef\n",
    "# inspired by https://github.com/keras-team/keras/issues/9395\n",
    "def dice_coef_healthy(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,0] * y_pred[0,:,:,:,0]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,0])) + K.sum(K.square(y_pred[0,:,:,:,0])) + epsilon)\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,1] * y_pred[0,:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,1])) + K.sum(K.square(y_pred[0,:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,2] * y_pred[0,:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,2])) + K.sum(K.square(y_pred[0,:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,3] * y_pred[0,:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,3])) + K.sum(K.square(y_pred[0,:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=128 # Originally 240x240, we reduce this to reduce memory usage\n",
    "SLICES=128 # Originally 155, reduced for same reason. Must be a power of 2 (or at least divisible by 2, 3 times)\n",
    "SLICES_START=13 # We skip the first (and the last) few slices as they should contain less information\n",
    "BATCH_SIZE=1\n",
    "CHANNELS=4\n",
    "\n",
    "TRAIN_DATASET_PATH = os.getenv('TRAIN-PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "data_ids = pathListIntoIds(data_directories); \n",
    "\n",
    "    \n",
    "train_and_test_ids, val_ids = train_test_split(data_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(train_and_test_ids,test_size=0.2)\n",
    "\n",
    "\n",
    "keras = tf.compat.v1.keras\n",
    "Sequence = keras.utils.Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = BATCH_SIZE, n_channels = CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*SLICES, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');\n",
    "            ce = nib.load(data_path).get_fdata()   \n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1.nii.gz');\n",
    "            t1 = nib.load(data_path).get_fdata()       \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii.gz');\n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(SLICES):\n",
    "                X[j+(SLICES*c),:,:,0] = cv2.resize(flair[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,1] = cv2.resize(ce[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,2] = cv2.resize(t1[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,3] = cv2.resize(t2[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))                \n",
    "                \n",
    "                y[j +SLICES*c,:,:] = cv2.resize(seg[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        X = X.reshape(1,SLICES,IMG_SIZE,IMG_SIZE, CHANNELS)\n",
    "        y = y.reshape(1,SLICES,IMG_SIZE,IMG_SIZE)\n",
    "        # Generate masks\n",
    "        #y[y==4] = 3;\n",
    "        y = tf.one_hot(y, 4);\n",
    "\n",
    "        # Avoid dividing by zero - return early\n",
    "        if np.max(X) == 0.0:\n",
    "          return np.zeros(X.shape), y\n",
    "\n",
    "        return X/np.max(X), y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids)\n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c2)\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = UpSampling3D(2)(c11)\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = UpSampling3D(2)(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = UpSampling3D(2)(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "model = unet_3d(input_layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test (baseline) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1pykso74) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">honest-capybara-62</strong>: <a href=\"https://wandb.ai/vj-dl/BraTS2021/runs/1pykso74\" target=\"_blank\">https://wandb.ai/vj-dl/BraTS2021/runs/1pykso74</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221130_191138-1pykso74/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1pykso74). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/vj-dl/BraTS2021/runs/2omzn00z\" target=\"_blank\">hardy-morning-63</a></strong> to <a href=\"https://wandb.ai/vj-dl/BraTS2021\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                28, 4)]                                                           \n",
      "                                                                                                  \n",
      " conv3d_30 (Conv3D)             (None, 128, 128, 12  872         ['input_3[0][0]']                \n",
      "                                8, 8)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 128, 128, 12  32         ['conv3d_30[0][0]']              \n",
      " ormalization)                  8, 8)                                                             \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_28[0][0]'] \n",
      "                                8, 8)                                                             \n",
      "                                                                                                  \n",
      " conv3d_31 (Conv3D)             (None, 128, 128, 12  3472        ['activation_30[0][0]']          \n",
      "                                8, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 128, 128, 12  64         ['conv3d_31[0][0]']              \n",
      " ormalization)                  8, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_29[0][0]'] \n",
      "                                8, 16)                                                            \n",
      "                                                                                                  \n",
      " max_pooling3d_6 (MaxPooling3D)  (None, 64, 64, 64,   0          ['activation_31[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_32 (Conv3D)             (None, 64, 64, 64,   6928        ['max_pooling3d_6[0][0]']        \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 64, 64, 64,   64         ['conv3d_32[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_30[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_33 (Conv3D)             (None, 64, 64, 64,   13856       ['activation_32[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 64, 64, 64,   128        ['conv3d_33[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_31[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_7 (MaxPooling3D)  (None, 32, 32, 32,   0          ['activation_33[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_34 (Conv3D)             (None, 32, 32, 32,   27680       ['max_pooling3d_7[0][0]']        \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 32, 32, 32,   128        ['conv3d_34[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_32[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_35 (Conv3D)             (None, 32, 32, 32,   55360       ['activation_34[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 32, 32, 32,   256        ['conv3d_35[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_33[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_8 (MaxPooling3D)  (None, 16, 16, 16,   0          ['activation_35[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_36 (Conv3D)             (None, 16, 16, 16,   110656      ['max_pooling3d_8[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 16, 16, 16,   256        ['conv3d_36[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_34[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_37 (Conv3D)             (None, 16, 16, 16,   221312      ['activation_36[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 16, 16, 16,   512        ['conv3d_37[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 16, 16, 16,   0           ['batch_normalization_35[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " up_sampling3d_6 (UpSampling3D)  (None, 32, 32, 32,   0          ['activation_37[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 32, 32, 32,   0           ['activation_35[0][0]',          \n",
      "                                192)                              'up_sampling3d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_38 (Conv3D)             (None, 32, 32, 32,   331840      ['concatenate_6[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 32, 32, 32,   256        ['conv3d_38[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_36[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_39 (Conv3D)             (None, 32, 32, 32,   110656      ['activation_38[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 32, 32, 32,   256        ['conv3d_39[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 32, 32, 32,   0           ['batch_normalization_37[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " up_sampling3d_7 (UpSampling3D)  (None, 64, 64, 64,   0          ['activation_39[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 64, 64, 64,   0           ['activation_33[0][0]',          \n",
      "                                96)                               'up_sampling3d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_40 (Conv3D)             (None, 64, 64, 64,   82976       ['concatenate_7[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 64, 64, 64,   128        ['conv3d_40[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_38[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_41 (Conv3D)             (None, 64, 64, 64,   27680       ['activation_40[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 64, 64, 64,   128        ['conv3d_41[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 64, 64, 64,   0           ['batch_normalization_39[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " up_sampling3d_8 (UpSampling3D)  (None, 128, 128, 12  0          ['activation_41[0][0]']          \n",
      "                                8, 32)                                                            \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 128, 128, 12  0           ['activation_31[0][0]',          \n",
      "                                8, 48)                            'up_sampling3d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_42 (Conv3D)             (None, 128, 128, 12  20752       ['concatenate_8[0][0]']          \n",
      "                                8, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 128, 128, 12  64         ['conv3d_42[0][0]']              \n",
      " ormalization)                  8, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_40[0][0]'] \n",
      "                                8, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_43 (Conv3D)             (None, 128, 128, 12  6928        ['activation_42[0][0]']          \n",
      "                                8, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 128, 128, 12  64         ['conv3d_43[0][0]']              \n",
      " ormalization)                  8, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_41[0][0]'] \n",
      "                                8, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_44 (Conv3D)             (None, 128, 128, 12  68          ['activation_43[0][0]']          \n",
      "                                8, 4)                                                             \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 128, 128, 12  0           ['conv3d_44[0][0]']              \n",
      "                                8, 4)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,023,372\n",
      "Trainable params: 1,022,204\n",
      "Non-trainable params: 1,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9869 - mean_io_u_1: 0.3753 - dice_coef: 0.4100 - precision: 0.9912 - sensitivity: 0.9742 - specificity: 0.9974 - dice_coef_necrotic: 0.1634 - dice_coef_edema: 0.4151 - dice_coef_enhancing: 0.0748 - dice_coef_healthy: 0.9866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 575s 694ms/step - loss: 0.1014 - accuracy: 0.9869 - mean_io_u_1: 0.3753 - dice_coef: 0.4100 - precision: 0.9912 - sensitivity: 0.9742 - specificity: 0.9974 - dice_coef_necrotic: 0.1634 - dice_coef_edema: 0.4151 - dice_coef_enhancing: 0.0748 - dice_coef_healthy: 0.9866 - val_loss: 0.0899 - val_accuracy: 0.9707 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3720 - val_precision: 0.9768 - val_sensitivity: 0.9682 - val_specificity: 0.9925 - val_dice_coef_necrotic: 0.1440 - val_dice_coef_edema: 0.2894 - val_dice_coef_enhancing: 0.0667 - val_dice_coef_healthy: 0.9878\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9917 - mean_io_u_1: 0.3753 - dice_coef: 0.4679 - precision: 0.9936 - sensitivity: 0.9915 - specificity: 0.9979 - dice_coef_necrotic: 0.2452 - dice_coef_edema: 0.5335 - dice_coef_enhancing: 0.0946 - dice_coef_healthy: 0.9982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 548s 685ms/step - loss: 0.0283 - accuracy: 0.9917 - mean_io_u_1: 0.3753 - dice_coef: 0.4679 - precision: 0.9936 - sensitivity: 0.9915 - specificity: 0.9979 - dice_coef_necrotic: 0.2452 - dice_coef_edema: 0.5335 - dice_coef_enhancing: 0.0946 - dice_coef_healthy: 0.9982 - val_loss: 0.0881 - val_accuracy: 0.9683 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3753 - val_precision: 0.9729 - val_sensitivity: 0.9666 - val_specificity: 0.9911 - val_dice_coef_necrotic: 0.1523 - val_dice_coef_edema: 0.3059 - val_dice_coef_enhancing: 0.0560 - val_dice_coef_healthy: 0.9871\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9919 - mean_io_u_1: 0.3753 - dice_coef: 0.4790 - precision: 0.9940 - sensitivity: 0.9918 - specificity: 0.9980 - dice_coef_necrotic: 0.2637 - dice_coef_edema: 0.5554 - dice_coef_enhancing: 0.0985 - dice_coef_healthy: 0.9984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 545s 681ms/step - loss: 0.0234 - accuracy: 0.9919 - mean_io_u_1: 0.3753 - dice_coef: 0.4790 - precision: 0.9940 - sensitivity: 0.9918 - specificity: 0.9980 - dice_coef_necrotic: 0.2637 - dice_coef_edema: 0.5554 - dice_coef_enhancing: 0.0985 - dice_coef_healthy: 0.9984 - val_loss: 0.0777 - val_accuracy: 0.9711 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3768 - val_precision: 0.9771 - val_sensitivity: 0.9683 - val_specificity: 0.9926 - val_dice_coef_necrotic: 0.1530 - val_dice_coef_edema: 0.2987 - val_dice_coef_enhancing: 0.0671 - val_dice_coef_healthy: 0.9885\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9922 - mean_io_u_1: 0.3753 - dice_coef: 0.4857 - precision: 0.9942 - sensitivity: 0.9921 - specificity: 0.9981 - dice_coef_necrotic: 0.2693 - dice_coef_edema: 0.5726 - dice_coef_enhancing: 0.1023 - dice_coef_healthy: 0.9984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 538s 672ms/step - loss: 0.0213 - accuracy: 0.9922 - mean_io_u_1: 0.3753 - dice_coef: 0.4857 - precision: 0.9942 - sensitivity: 0.9921 - specificity: 0.9981 - dice_coef_necrotic: 0.2693 - dice_coef_edema: 0.5726 - dice_coef_enhancing: 0.1023 - dice_coef_healthy: 0.9984 - val_loss: 0.0663 - val_accuracy: 0.9767 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3760 - val_precision: 0.9788 - val_sensitivity: 0.9759 - val_specificity: 0.9930 - val_dice_coef_necrotic: 0.1471 - val_dice_coef_edema: 0.3113 - val_dice_coef_enhancing: 0.0547 - val_dice_coef_healthy: 0.9910\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 541s 676ms/step - loss: 0.0203 - accuracy: 0.9924 - mean_io_u_1: 0.3753 - dice_coef: 0.4913 - precision: 0.9943 - sensitivity: 0.9923 - specificity: 0.9981 - dice_coef_necrotic: 0.2741 - dice_coef_edema: 0.5848 - dice_coef_enhancing: 0.1078 - dice_coef_healthy: 0.9985 - val_loss: 0.0751 - val_accuracy: 0.9720 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3899 - val_precision: 0.9776 - val_sensitivity: 0.9692 - val_specificity: 0.9927 - val_dice_coef_necrotic: 0.1679 - val_dice_coef_edema: 0.3291 - val_dice_coef_enhancing: 0.0738 - val_dice_coef_healthy: 0.9890\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 544s 679ms/step - loss: 0.0197 - accuracy: 0.9925 - mean_io_u_1: 0.3753 - dice_coef: 0.4972 - precision: 0.9944 - sensitivity: 0.9923 - specificity: 0.9982 - dice_coef_necrotic: 0.2749 - dice_coef_edema: 0.5956 - dice_coef_enhancing: 0.1198 - dice_coef_healthy: 0.9984 - val_loss: 0.0771 - val_accuracy: 0.9726 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3979 - val_precision: 0.9784 - val_sensitivity: 0.9698 - val_specificity: 0.9930 - val_dice_coef_necrotic: 0.1764 - val_dice_coef_edema: 0.3451 - val_dice_coef_enhancing: 0.0811 - val_dice_coef_healthy: 0.9890\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 552s 690ms/step - loss: 0.0195 - accuracy: 0.9928 - mean_io_u_1: 0.3753 - dice_coef: 0.5063 - precision: 0.9946 - sensitivity: 0.9922 - specificity: 0.9982 - dice_coef_necrotic: 0.2687 - dice_coef_edema: 0.6116 - dice_coef_enhancing: 0.1466 - dice_coef_healthy: 0.9984 - val_loss: 0.0790 - val_accuracy: 0.9733 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.4015 - val_precision: 0.9822 - val_sensitivity: 0.9669 - val_specificity: 0.9943 - val_dice_coef_necrotic: 0.1622 - val_dice_coef_edema: 0.3397 - val_dice_coef_enhancing: 0.1154 - val_dice_coef_healthy: 0.9887\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 547s 684ms/step - loss: 0.0197 - accuracy: 0.9929 - mean_io_u_1: 0.3753 - dice_coef: 0.5135 - precision: 0.9947 - sensitivity: 0.9924 - specificity: 0.9983 - dice_coef_necrotic: 0.2599 - dice_coef_edema: 0.6282 - dice_coef_enhancing: 0.1677 - dice_coef_healthy: 0.9983 - val_loss: 0.0757 - val_accuracy: 0.9752 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3905 - val_precision: 0.9786 - val_sensitivity: 0.9731 - val_specificity: 0.9930 - val_dice_coef_necrotic: 0.1319 - val_dice_coef_edema: 0.3698 - val_dice_coef_enhancing: 0.0707 - val_dice_coef_healthy: 0.9898\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 545s 681ms/step - loss: 0.0197 - accuracy: 0.9924 - mean_io_u_1: 0.3753 - dice_coef: 0.5058 - precision: 0.9950 - sensitivity: 0.9924 - specificity: 0.9983 - dice_coef_necrotic: 0.2729 - dice_coef_edema: 0.6201 - dice_coef_enhancing: 0.1315 - dice_coef_healthy: 0.9985 - val_loss: 0.0839 - val_accuracy: 0.9702 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3740 - val_precision: 0.9853 - val_sensitivity: 0.9640 - val_specificity: 0.9953 - val_dice_coef_necrotic: 0.1576 - val_dice_coef_edema: 0.2371 - val_dice_coef_enhancing: 0.1131 - val_dice_coef_healthy: 0.9881\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 544s 680ms/step - loss: 0.0191 - accuracy: 0.9923 - mean_io_u_1: 0.3753 - dice_coef: 0.5268 - precision: 0.9959 - sensitivity: 0.9918 - specificity: 0.9987 - dice_coef_necrotic: 0.3074 - dice_coef_edema: 0.6050 - dice_coef_enhancing: 0.1962 - dice_coef_healthy: 0.9985 - val_loss: 0.0991 - val_accuracy: 0.9647 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3978 - val_precision: 0.9782 - val_sensitivity: 0.9591 - val_specificity: 0.9931 - val_dice_coef_necrotic: 0.1822 - val_dice_coef_edema: 0.3086 - val_dice_coef_enhancing: 0.1148 - val_dice_coef_healthy: 0.9854\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 542s 678ms/step - loss: 0.0189 - accuracy: 0.9924 - mean_io_u_1: 0.3753 - dice_coef: 0.5263 - precision: 0.9956 - sensitivity: 0.9918 - specificity: 0.9986 - dice_coef_necrotic: 0.3182 - dice_coef_edema: 0.6055 - dice_coef_enhancing: 0.1830 - dice_coef_healthy: 0.9985 - val_loss: 0.0824 - val_accuracy: 0.9703 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.4058 - val_precision: 0.9803 - val_sensitivity: 0.9649 - val_specificity: 0.9937 - val_dice_coef_necrotic: 0.1888 - val_dice_coef_edema: 0.3313 - val_dice_coef_enhancing: 0.1153 - val_dice_coef_healthy: 0.9878\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 547s 684ms/step - loss: 0.0183 - accuracy: 0.9926 - mean_io_u_1: 0.3753 - dice_coef: 0.5333 - precision: 0.9959 - sensitivity: 0.9921 - specificity: 0.9987 - dice_coef_necrotic: 0.3267 - dice_coef_edema: 0.6139 - dice_coef_enhancing: 0.1941 - dice_coef_healthy: 0.9985 - val_loss: 0.0866 - val_accuracy: 0.9682 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.4114 - val_precision: 0.9786 - val_sensitivity: 0.9646 - val_specificity: 0.9931 - val_dice_coef_necrotic: 0.2001 - val_dice_coef_edema: 0.3396 - val_dice_coef_enhancing: 0.1186 - val_dice_coef_healthy: 0.9872\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 542s 677ms/step - loss: 0.0182 - accuracy: 0.9926 - mean_io_u_1: 0.3753 - dice_coef: 0.5344 - precision: 0.9961 - sensitivity: 0.9920 - specificity: 0.9987 - dice_coef_necrotic: 0.3323 - dice_coef_edema: 0.6087 - dice_coef_enhancing: 0.1981 - dice_coef_healthy: 0.9985 - val_loss: 0.0744 - val_accuracy: 0.9720 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.4166 - val_precision: 0.9808 - val_sensitivity: 0.9697 - val_specificity: 0.9938 - val_dice_coef_necrotic: 0.2099 - val_dice_coef_edema: 0.3471 - val_dice_coef_enhancing: 0.1199 - val_dice_coef_healthy: 0.9893\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 542s 677ms/step - loss: 0.0182 - accuracy: 0.9925 - mean_io_u_1: 0.3753 - dice_coef: 0.5362 - precision: 0.9960 - sensitivity: 0.9920 - specificity: 0.9987 - dice_coef_necrotic: 0.3354 - dice_coef_edema: 0.6097 - dice_coef_enhancing: 0.2012 - dice_coef_healthy: 0.9985 - val_loss: 0.0777 - val_accuracy: 0.9695 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.4211 - val_precision: 0.9805 - val_sensitivity: 0.9657 - val_specificity: 0.9937 - val_dice_coef_necrotic: 0.2117 - val_dice_coef_edema: 0.3479 - val_dice_coef_enhancing: 0.1365 - val_dice_coef_healthy: 0.9883\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 545s 680ms/step - loss: 0.0184 - accuracy: 0.9925 - mean_io_u_1: 0.3753 - dice_coef: 0.5332 - precision: 0.9960 - sensitivity: 0.9918 - specificity: 0.9987 - dice_coef_necrotic: 0.3279 - dice_coef_edema: 0.6025 - dice_coef_enhancing: 0.2041 - dice_coef_healthy: 0.9985 - val_loss: 0.1131 - val_accuracy: 0.9562 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.4222 - val_precision: 0.9740 - val_sensitivity: 0.9521 - val_specificity: 0.9918 - val_dice_coef_necrotic: 0.2232 - val_dice_coef_edema: 0.3380 - val_dice_coef_enhancing: 0.1454 - val_dice_coef_healthy: 0.9824\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 544s 679ms/step - loss: 0.0196 - accuracy: 0.9922 - mean_io_u_1: 0.3753 - dice_coef: 0.5234 - precision: 0.9958 - sensitivity: 0.9913 - specificity: 0.9986 - dice_coef_necrotic: 0.3149 - dice_coef_edema: 0.5803 - dice_coef_enhancing: 0.2003 - dice_coef_healthy: 0.9983 - val_loss: 0.1026 - val_accuracy: 0.9603 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3964 - val_precision: 0.9780 - val_sensitivity: 0.9532 - val_specificity: 0.9931 - val_dice_coef_necrotic: 0.1844 - val_dice_coef_edema: 0.2894 - val_dice_coef_enhancing: 0.1281 - val_dice_coef_healthy: 0.9838\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 547s 684ms/step - loss: 0.0195 - accuracy: 0.9921 - mean_io_u_1: 0.3753 - dice_coef: 0.5241 - precision: 0.9956 - sensitivity: 0.9915 - specificity: 0.9985 - dice_coef_necrotic: 0.3112 - dice_coef_edema: 0.5800 - dice_coef_enhancing: 0.2071 - dice_coef_healthy: 0.9983 - val_loss: 0.0759 - val_accuracy: 0.9721 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.4260 - val_precision: 0.9802 - val_sensitivity: 0.9676 - val_specificity: 0.9936 - val_dice_coef_necrotic: 0.2158 - val_dice_coef_edema: 0.3665 - val_dice_coef_enhancing: 0.1330 - val_dice_coef_healthy: 0.9889\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 540s 674ms/step - loss: 0.0195 - accuracy: 0.9920 - mean_io_u_1: 0.3753 - dice_coef: 0.5240 - precision: 0.9956 - sensitivity: 0.9915 - specificity: 0.9985 - dice_coef_necrotic: 0.3080 - dice_coef_edema: 0.5797 - dice_coef_enhancing: 0.2102 - dice_coef_healthy: 0.9983 - val_loss: 0.0816 - val_accuracy: 0.9696 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.4051 - val_precision: 0.9807 - val_sensitivity: 0.9648 - val_specificity: 0.9938 - val_dice_coef_necrotic: 0.1955 - val_dice_coef_edema: 0.2814 - val_dice_coef_enhancing: 0.1557 - val_dice_coef_healthy: 0.9879\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 546s 683ms/step - loss: 0.0214 - accuracy: 0.9917 - mean_io_u_1: 0.3753 - dice_coef: 0.5114 - precision: 0.9951 - sensitivity: 0.9909 - specificity: 0.9984 - dice_coef_necrotic: 0.2922 - dice_coef_edema: 0.5510 - dice_coef_enhancing: 0.2042 - dice_coef_healthy: 0.9981 - val_loss: 0.0897 - val_accuracy: 0.9642 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3965 - val_precision: 0.9716 - val_sensitivity: 0.9592 - val_specificity: 0.9909 - val_dice_coef_necrotic: 0.1699 - val_dice_coef_edema: 0.3240 - val_dice_coef_enhancing: 0.1067 - val_dice_coef_healthy: 0.9855\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9915 - mean_io_u_1: 0.3753 - dice_coef: 0.5114 - precision: 0.9948 - sensitivity: 0.9909 - specificity: 0.9983 - dice_coef_necrotic: 0.2801 - dice_coef_edema: 0.5603 - dice_coef_enhancing: 0.2070 - dice_coef_healthy: 0.9980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221130_191256-2omzn00z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 557s 696ms/step - loss: 0.0215 - accuracy: 0.9915 - mean_io_u_1: 0.3753 - dice_coef: 0.5114 - precision: 0.9948 - sensitivity: 0.9909 - specificity: 0.9983 - dice_coef_necrotic: 0.2801 - dice_coef_edema: 0.5603 - dice_coef_enhancing: 0.2070 - dice_coef_healthy: 0.9980 - val_loss: 0.0644 - val_accuracy: 0.9832 - val_mean_io_u_1: 0.3753 - val_dice_coef: 0.3525 - val_precision: 0.9844 - val_sensitivity: 0.9829 - val_specificity: 0.9949 - val_dice_coef_necrotic: 0.0965 - val_dice_coef_edema: 0.2793 - val_dice_coef_enhancing: 0.0415 - val_dice_coef_healthy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 20\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=LR), loss=\"categorical_crossentropy\", metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "model.summary()\n",
    "model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[WandbCallback()])\n",
    "model.save(\"baseline_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 87s 434ms/step - loss: 0.0787 - accuracy: 0.9800 - mean_io_u_1: 0.3753 - dice_coef: 0.3339 - precision: 0.9809 - sensitivity: 0.9795 - specificity: 0.9937 - dice_coef_necrotic: 0.0800 - dice_coef_edema: 0.2303 - dice_coef_enhancing: 0.0344 - dice_coef_healthy: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07869383692741394,\n",
       " 0.9800161123275757,\n",
       " 0.37527090311050415,\n",
       " 0.3339027464389801,\n",
       " 0.9809294939041138,\n",
       " 0.9795030951499939,\n",
       " 0.9937281012535095,\n",
       " 0.0800149142742157,\n",
       " 0.23031704127788544,\n",
       " 0.034410323947668076,\n",
       " 0.9908667802810669]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Callbacks for improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='dice_coef', min_delta=0,\n",
    "                               patience=2, verbose=1, mode='auto'),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    # Maybe use Convolution with stride = 2 in improved model\n",
    "    #c3 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c2)\n",
    "    c3 = Conv3D(16, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c2)\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    #c6 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c5)\n",
    "    c6 = Conv3D(32, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    #c9 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c8)\n",
    "    c9 = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    #c12 = Conv3DTranspose(filters=128, kernel_size=(1,1,1), strides=(2,2,2))(c11)\n",
    "    c12 = UpSampling3D(2)(c11)\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = UpSampling3D(2)(c15)\n",
    "    #c16 = Conv3DTranspose(filters=64, kernel_size=(1,1,1), strides=(2,2,2))(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = UpSampling3D(2)(c19)\n",
    "    #c20 = Conv3DTranspose(filters=32, kernel_size=(1,1,1), strides=(2,2,2))(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "model = unet_3d(input_layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 20\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=LR, momentum=0.95), loss=focal_loss, metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "model.summary()\n",
    "model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[callbacks, WandbCallback()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions? Maybe we should do an example (or a few) where we use the trained model to predict segmentation masks on data we have not trained on (i.e. the two brain scans that were included in the data set but not in the training-data file**\n",
    "\n",
    "**Something like this:** https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/ **(scroll down to \"predictions\")**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4270e3f338dc97884e39dfa435881d633bb85d0979a79226f74580c90b39f6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
