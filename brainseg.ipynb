{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage \n",
    "from skimage.transform import rotate\n",
    "import keras\n",
    "import random\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union, Text\n",
    "from official.modeling import tf_utils\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import cv2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unpack data** \n",
    "\n",
    "*NB: Size is 13.5 GB, code is commented out to prevent accidental unpacking*\n",
    "\n",
    "**TEST THIS BEFORE HAND IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tarfile\n",
    "#file = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')\n",
    "\n",
    "#file.extractall(os.getenv('TRAIN-PATH'))\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics and loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "        =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    axis = (0,1,2,3)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "# Loss functions here: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook\n",
    "\n",
    "ALPHA = 0.7\n",
    "BETA = 0.3\n",
    "GAMMA = 1\n",
    "\n",
    "def focal_tversky_loss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):\n",
    "    \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))\n",
    "               \n",
    "        Tversky = (TP + smooth) / (TP + beta*FP + alpha*FN + smooth)  \n",
    "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
    "        \n",
    "        return FocalTversky\n",
    "\n",
    "\n",
    "\n",
    "# define per class evaluation of dice coef\n",
    "# inspired by https://github.com/keras-team/keras/issues/9395\n",
    "def dice_coef_healthy(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,0] * y_pred[0,:,:,:,0]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,0])) + K.sum(K.square(y_pred[0,:,:,:,0])) + epsilon)\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,1] * y_pred[0,:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,1])) + K.sum(K.square(y_pred[0,:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,2] * y_pred[0,:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,2])) + K.sum(K.square(y_pred[0,:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,3] * y_pred[0,:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,3])) + K.sum(K.square(y_pred[0,:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=128 # Originally 240x240, we reduce this to reduce memory usage\n",
    "SLICES=128 # Originally 155, reduced for same reason. Must be a power of 2 (or at least divisible by 2, 3 times)\n",
    "SLICES_START=13 # We skip the first (and the last) few slices as they should contain less information\n",
    "BATCH_SIZE=1\n",
    "CHANNELS=4\n",
    "DATA_AUG=False # Enables data augmentation\n",
    "DATA_AUG_FACTOR=0 # If we have n data elements, we will have DATA_AUG_FACTOR*n data elements to train on\n",
    "\n",
    "TRAIN_DATASET_PATH = os.getenv('TRAIN-PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomBrightness(X, y):\n",
    "  X = tf.image.stateless_random_brightness(X, 0.2, seed=(1,2)).numpy()\n",
    "  y = tf.image.stateless_random_brightness(y, 0.2, seed=(1,2)).numpy()\n",
    "  return X, y\n",
    "\n",
    "def RandomRotate(X, y):\n",
    "    r = random.randint(0,3)\n",
    "    # rotate by 90 degrees times random r\n",
    "    X = np.rot90(X, k=r)\n",
    "    y = np.rot90(y, k=r)\n",
    "    return X, y \n",
    "    \n",
    "def AugmentData(X, y):\n",
    "  X, y = RandomRotate(X, y)\n",
    "  X, y = RandomBrightness(X, y)\n",
    "  return X, y\n",
    "  \n",
    "data_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "data_ids = pathListIntoIds(data_directories); \n",
    "\n",
    "    \n",
    "train_and_test_ids, val_ids = train_test_split(data_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(train_and_test_ids,test_size=0.2)\n",
    "\n",
    "\n",
    "keras = tf.compat.v1.keras\n",
    "Sequence = keras.utils.Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = BATCH_SIZE, n_channels = CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*SLICES, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');\n",
    "            ce = nib.load(data_path).get_fdata()   \n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1.nii.gz');\n",
    "            t1 = nib.load(data_path).get_fdata()       \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii.gz');\n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(SLICES):\n",
    "                X[j+(SLICES*c),:,:,0] = cv2.resize(flair[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,1] = cv2.resize(ce[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,2] = cv2.resize(t1[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,3] = cv2.resize(t2[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))                \n",
    "                \n",
    "                y[j +SLICES*c,:,:] = cv2.resize(seg[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        if DATA_AUG: X, y = AugmentData(X, y)\n",
    "\n",
    "        X = X.reshape(1,SLICES,IMG_SIZE,IMG_SIZE, CHANNELS)\n",
    "        y = y.reshape(1,SLICES,IMG_SIZE,IMG_SIZE)\n",
    "        # Generate masks\n",
    "        #y[y==4] = 3;\n",
    "        y = tf.one_hot(y, 4);\n",
    "\n",
    "        # Avoid dividing by zero - return early\n",
    "        if np.max(X) == 0.0:\n",
    "          return np.zeros(X.shape), y\n",
    "\n",
    "        return X/np.max(X), y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids*DATA_AUG_FACTOR) if DATA_AUG else DataGenerator(train_ids) \n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c2)\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = UpSampling3D(2)(c11)\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = UpSampling3D(2)(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = UpSampling3D(2)(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "model = unet_3d(input_layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test (baseline) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = False # Whether to save the model after training\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=LR), loss=\"categorical_crossentropy\", metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "model.summary()\n",
    "model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[WandbCallback()])\n",
    "if SAVE_MODEL:\n",
    "  model.save(\"baseline_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruct model and test it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"baseline_model.h5\", custom_objects={\"dice_coef\":dice_coef, \n",
    "                                                                                \"precision\":precision, \n",
    "                                                                                \"sensitivity\":sensitivity, \n",
    "                                                                                \"specificity\":specificity,\n",
    "                                                                                \"dice_coef_necrotic\":dice_coef_necrotic, \n",
    "                                                                                \"dice_coef_edema\":dice_coef_edema, \n",
    "                                                                                \"dice_coef_enhancing\":dice_coef_enhancing,\n",
    "                                                                                \"dice_coef_healthy\": dice_coef_healthy})\n",
    "reconstructed_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Callbacks for improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,\n",
    "                               patience=2, verbose=1, mode='auto'),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reverse blocks for improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualInner(tf.keras.layers.Layer):\n",
    "  \"\"\"Creates a single inner block of a residual.\n",
    "  This corresponds to `F`/`G` functions in the RevNet paper:\n",
    "  Aidan N. Gomez, Mengye Ren, Raquel Urtasun, Roger B. Grosse.\n",
    "  The Reversible Residual Network: Backpropagation Without Storing Activations.\n",
    "  (https://arxiv.org/pdf/1707.04585.pdf)\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      filters: int,\n",
    "      strides: int,\n",
    "      kernel_initializer: Union[str, Callable[\n",
    "          ..., tf.keras.initializers.Initializer]] = 'VarianceScaling',\n",
    "      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,\n",
    "      activation: Union[str, Callable[..., tf.Tensor]] = 'relu',\n",
    "      use_sync_bn: bool = False,\n",
    "      norm_momentum: float = 0.99,\n",
    "      norm_epsilon: float = 0.001,\n",
    "      batch_norm_first: bool = True,\n",
    "      **kwargs):\n",
    "    \"\"\"Initializes a ResidualInner.\n",
    "    Args:\n",
    "      filters: An `int` of output filter size.\n",
    "      strides: An `int` of stride size for convolution for the residual block.\n",
    "      kernel_initializer: A `str` or `tf.keras.initializers.Initializer`\n",
    "        instance for convolutional layers.\n",
    "      kernel_regularizer: A `tf.keras.regularizers.Regularizer` for Conv2D.\n",
    "      activation: A `str` or `callable` instance of the activation function.\n",
    "      use_sync_bn: A `bool`. If True, use synchronized batch normalization.\n",
    "      norm_momentum: A `float` of normalization momentum for the moving average.\n",
    "      norm_epsilon: A `float` added to variance to avoid dividing by zero.\n",
    "      batch_norm_first: A `bool` of whether to apply activation and batch norm\n",
    "        before conv.\n",
    "      **kwargs: Additional keyword arguments to be passed.\n",
    "    \"\"\"\n",
    "    super(ResidualInner, self).__init__(**kwargs)\n",
    "\n",
    "    self.strides = strides\n",
    "    self.filters = filters\n",
    "    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "    self._kernel_regularizer = kernel_regularizer\n",
    "    self._activation = tf.keras.activations.get(activation)\n",
    "    self._use_sync_bn = use_sync_bn\n",
    "    self._norm_momentum = norm_momentum\n",
    "    self._norm_epsilon = norm_epsilon\n",
    "    self._batch_norm_first = batch_norm_first\n",
    "\n",
    "    if use_sync_bn:\n",
    "      self._norm = tf.keras.layers.experimental.SyncBatchNormalization\n",
    "    else:\n",
    "      self._norm = tf.keras.layers.BatchNormalization\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
    "      self._bn_axis = -1\n",
    "    else:\n",
    "      self._bn_axis = 1\n",
    "    self._activation_fn = tf_utils.get_activation(activation)\n",
    "\n",
    "  def build(self, input_shape: tf.TensorShape):\n",
    "    if self._batch_norm_first:\n",
    "      self._batch_norm_0 = self._norm(\n",
    "          axis=self._bn_axis,\n",
    "          momentum=self._norm_momentum,\n",
    "          epsilon=self._norm_epsilon)\n",
    "\n",
    "    self._conv3d_1 = Conv3D(\n",
    "        filters=self.filters,\n",
    "        kernel_size=3,\n",
    "        strides=self.strides,\n",
    "        use_bias=False,\n",
    "        padding='same',\n",
    "        kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),\n",
    "        kernel_regularizer=self._kernel_regularizer)\n",
    "\n",
    "    self._batch_norm_1 = self._norm(\n",
    "        axis=self._bn_axis,\n",
    "        momentum=self._norm_momentum,\n",
    "        epsilon=self._norm_epsilon)\n",
    "\n",
    "    self._conv3d_2 = Conv3D(\n",
    "        filters=self.filters,\n",
    "        kernel_size=3,\n",
    "        strides=1,\n",
    "        use_bias=False,\n",
    "        padding='same',\n",
    "        kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),\n",
    "        kernel_regularizer=self._kernel_regularizer)\n",
    "\n",
    "    super(ResidualInner, self).build(input_shape)\n",
    "\n",
    "  def get_config(self) -> Dict[str, Any]:\n",
    "    config = {\n",
    "        'filters': self.filters,\n",
    "        'strides': self.strides,\n",
    "        'kernel_initializer': self._kernel_initializer,\n",
    "        'kernel_regularizer': self._kernel_regularizer,\n",
    "        'activation': self._activation,\n",
    "        'use_sync_bn': self._use_sync_bn,\n",
    "        'norm_momentum': self._norm_momentum,\n",
    "        'norm_epsilon': self._norm_epsilon,\n",
    "        'batch_norm_first': self._batch_norm_first,\n",
    "    }\n",
    "    base_config = super(ResidualInner, self).get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "  def call(self,\n",
    "           inputs: tf.Tensor,\n",
    "           training: Optional[bool] = None) -> tf.Tensor:\n",
    "    x = inputs\n",
    "    if self._batch_norm_first:\n",
    "      x = self._batch_norm_0(x, training=training)\n",
    "      x = self._activation_fn(x)\n",
    "    x = self._conv3d_1(x)\n",
    "\n",
    "    x = self._batch_norm_1(x, training=training)\n",
    "    x = self._activation_fn(x)\n",
    "    x = self._conv3d_2(x)\n",
    "    return x\n",
    " \n",
    "class ReversibleLayer(tf.keras.layers.Layer):\n",
    "  \"\"\"Creates a reversible layer.\n",
    "  Computes y1 = x1 + f(x2), y2 = x2 + g(y1), where f and g can be arbitrary\n",
    "  layers that are stateless, which in this case are `ResidualInner` layers.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               f: tf.keras.layers.Layer,\n",
    "               g: tf.keras.layers.Layer,\n",
    "               manual_grads: bool = True,\n",
    "               **kwargs):\n",
    "    \"\"\"Initializes a ReversibleLayer.\n",
    "    Args:\n",
    "      f: A `tf.keras.layers.Layer` instance of `f` inner block referred to in\n",
    "        paper. Each reversible layer consists of two inner functions. For\n",
    "        example, in RevNet the reversible residual consists of two f/g inner\n",
    "        (bottleneck) residual functions. Where the input to the reversible layer\n",
    "        is x, the input gets partitioned in the channel dimension and the\n",
    "        forward pass follows (eq8): x = [x1; x2], z1 = x1 + f(x2), y2 = x2 +\n",
    "        g(z1), y1 = stop_gradient(z1).\n",
    "      g: A `tf.keras.layers.Layer` instance of `g` inner block referred to in\n",
    "        paper. Detailed explanation same as above as `f` arg.\n",
    "      manual_grads: A `bool` [Testing Only] of whether to manually take\n",
    "        gradients as in Algorithm 1 or defer to autograd.\n",
    "      **kwargs: Additional keyword arguments to be passed.\n",
    "    \"\"\"\n",
    "    super(ReversibleLayer, self).__init__(**kwargs)\n",
    "\n",
    "    self._f = f\n",
    "    self._g = g\n",
    "    self._manual_grads = manual_grads\n",
    "\n",
    "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
    "      self._axis = -1\n",
    "    else:\n",
    "      self._axis = 1\n",
    "\n",
    "  def get_config(self) -> Dict[str, Any]:\n",
    "    config = {\n",
    "        'f': self._f,\n",
    "        'g': self._g,\n",
    "        'manual_grads': self._manual_grads,\n",
    "    }\n",
    "    base_config = super(ReversibleLayer, self).get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "  def _ckpt_non_trainable_vars(self):\n",
    "    self._f_non_trainable_vars = [\n",
    "        v.read_value() for v in self._f.non_trainable_variables\n",
    "    ]\n",
    "    self._g_non_trainable_vars = [\n",
    "        v.read_value() for v in self._g.non_trainable_variables\n",
    "    ]\n",
    "\n",
    "  def _load_ckpt_non_trainable_vars(self):\n",
    "    for v, v_chkpt in zip(self._f.non_trainable_variables,\n",
    "                          self._f_non_trainable_vars):\n",
    "      v.assign(v_chkpt)\n",
    "    for v, v_chkpt in zip(self._g.non_trainable_variables,\n",
    "                          self._g_non_trainable_vars):\n",
    "      v.assign(v_chkpt)\n",
    "\n",
    "  def call(self,\n",
    "           inputs: tf.Tensor,\n",
    "           training: Optional[bool] = None) -> tf.Tensor:\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def reversible(\n",
    "        x: tf.Tensor\n",
    "    ) -> Tuple[tf.Tensor, Callable[[Any], Tuple[List[tf.Tensor],\n",
    "                                                List[tf.Tensor]]]]:\n",
    "      \"\"\"Implements Algorithm 1 in the RevNet paper.\n",
    "         Aidan N. Gomez, Mengye Ren, Raquel Urtasun, Roger B. Grosse.\n",
    "         The Reversible Residual Network: Backpropagation Without Storing\n",
    "         Activations.\n",
    "         (https://arxiv.org/pdf/1707.04585.pdf)\n",
    "      Args:\n",
    "        x: An input `tf.Tensor.\n",
    "      Returns:\n",
    "        y: The output [y1; y2] in Algorithm 1.\n",
    "        grad_fn: A callable function that computes the gradients.\n",
    "      \"\"\"\n",
    "      with tf.GradientTape() as fwdtape:\n",
    "        fwdtape.watch(x)\n",
    "        x1, x2 = tf.split(x, num_or_size_splits=2, axis=self._axis)\n",
    "        f_x2 = self._f(x2, training=training)\n",
    "        #x1_down = _maybe_downsample(x1, f_x2.shape[self._axis], self._f.strides,\n",
    "        #                            self._axis)\n",
    "        z1 = f_x2 + x1\n",
    "        g_z1 = self._g(z1, training=training)\n",
    "        #x2_down = _maybe_downsample(x2, g_z1.shape[self._axis], self._f.strides,\n",
    "        #                            self._axis)\n",
    "        y2 = x2 + g_z1\n",
    "\n",
    "        # Equation 8: https://arxiv.org/pdf/1707.04585.pdf\n",
    "        # Decouple y1 and z1 so that their derivatives are different.\n",
    "        y1 = tf.identity(z1)\n",
    "        y = tf.concat([y1, y2], axis=self._axis)\n",
    "\n",
    "        irreversible = ((self._f.strides != 1 or self._g.strides != 1) or\n",
    "                        (y.shape[self._axis] != inputs.shape[self._axis]))\n",
    "\n",
    "        # Checkpointing moving mean/variance for batch normalization layers\n",
    "        # as they shouldn't be updated during the custom gradient pass of f/g.\n",
    "        self._ckpt_non_trainable_vars()\n",
    "\n",
    "      def grad_fn(\n",
    "          dy: tf.Tensor,\n",
    "          variables: Optional[List[tf.Variable]] = None,\n",
    "      ) -> Tuple[List[tf.Tensor], List[tf.Tensor]]:\n",
    "        \"\"\"Given dy calculate (dy/dx)|_{x_{input}} using f/g.\"\"\"\n",
    "        if irreversible or not self._manual_grads:\n",
    "          grads_combined = fwdtape.gradient(\n",
    "              y, [x] + variables, output_gradients=dy)\n",
    "          dx = grads_combined[0]\n",
    "          grad_vars = grads_combined[1:]\n",
    "        else:\n",
    "          y1_nograd = tf.stop_gradient(y1)\n",
    "          y2_nograd = tf.stop_gradient(y2)\n",
    "          dy1, dy2 = tf.split(dy, num_or_size_splits=2, axis=self._axis)\n",
    "\n",
    "          # Index mapping from self.f/g.trainable_variables to grad_fn\n",
    "          # input `variables` kwarg so that we can reorder dwf + dwg\n",
    "          # variable gradient list to match `variables` order.\n",
    "          f_var_refs = [v.ref() for v in self._f.trainable_variables]\n",
    "          g_var_refs = [v.ref() for v in self._g.trainable_variables]\n",
    "          fg_var_refs = f_var_refs + g_var_refs\n",
    "          self_to_var_index = [fg_var_refs.index(v.ref()) for v in variables]\n",
    "\n",
    "          # Algorithm 1 in paper (line # documented in-line)\n",
    "          z1 = y1_nograd  # line 2\n",
    "          with tf.GradientTape() as gtape:\n",
    "            gtape.watch(z1)\n",
    "            g_z1 = self._g(z1, training=training)\n",
    "          x2 = y2_nograd - g_z1  # line 3\n",
    "\n",
    "          with tf.GradientTape() as ftape:\n",
    "            ftape.watch(x2)\n",
    "            f_x2 = self._f(x2, training=training)\n",
    "          x1 = z1 - f_x2  # pylint: disable=unused-variable      # line 4\n",
    "\n",
    "          # Compute gradients\n",
    "          g_grads_combined = gtape.gradient(\n",
    "              g_z1, [z1] + self._g.trainable_variables, output_gradients=dy2)\n",
    "          dz1 = dy1 + g_grads_combined[0]  # line 5\n",
    "          dwg = g_grads_combined[1:]  # line 9\n",
    "\n",
    "          f_grads_combined = ftape.gradient(\n",
    "              f_x2, [x2] + self._f.trainable_variables, output_gradients=dz1)\n",
    "          dx2 = dy2 + f_grads_combined[0]  # line 6\n",
    "          dwf = f_grads_combined[1:]  # line 8\n",
    "          dx1 = dz1  # line 7\n",
    "\n",
    "          # Pack the input and variable gradients.\n",
    "          dx = tf.concat([dx1, dx2], axis=self._axis)\n",
    "          grad_vars = dwf + dwg\n",
    "          # Reorder gradients (trainable_variables to variables kwarg order)\n",
    "          grad_vars = [grad_vars[i] for i in self_to_var_index]\n",
    "\n",
    "          # Restore batch normalization moving mean/variance for correctness.\n",
    "          self._load_ckpt_non_trainable_vars()\n",
    "\n",
    "        return dx, grad_vars  # grad_fn end\n",
    "\n",
    "      return y, grad_fn  # reversible end\n",
    "\n",
    "    activations = reversible(inputs)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    #c1 = unet_3d_conv(input_img, 8)\n",
    "    #c2 = unet_3d_conv(c1, 16)\n",
    "    c1 = Conv3D(16, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(input_img)\n",
    "    \n",
    "    resF = ResidualInner(filters=8, strides=1)\n",
    "    resG = ResidualInner(filters=8, strides=1)\n",
    "    rev1 = ReversibleLayer(resF, resG)(c1)\n",
    "    \n",
    "    m1 = MaxPool3D((2,2,2))(rev1)\n",
    "    c2 = Conv3D(32, kernel_size=(1,1,1), strides=(1,1,1),padding='same')(m1)\n",
    "    \n",
    "    resF = ResidualInner(filters=16, strides=1)\n",
    "    resG = ResidualInner(filters=16, strides=1)\n",
    "    rev2 = ReversibleLayer(resF, resG)(c2)\n",
    "    \n",
    "    m2 = MaxPool3D((2,2,2))(rev2)\n",
    "    c3 = Conv3D(64, kernel_size=(1,1,1), strides=(1,1,1),padding='same')(m2)\n",
    "    \n",
    "    resF = ResidualInner(filters=32, strides=1)\n",
    "    resG = ResidualInner(filters=32, strides=1)\n",
    "    rev3 = ReversibleLayer(resF, resG)(c3)\n",
    "    \n",
    "    m3 = MaxPool3D((2,2,2))(rev3)\n",
    "    c4 = Conv3D(128, kernel_size=(1,1,1), strides=(1,1,1),padding='same')(m3)\n",
    "    \n",
    "    resF = ResidualInner(filters=64, strides=1)\n",
    "    resG = ResidualInner(filters=64, strides=1)\n",
    "    rev4 = ReversibleLayer(resF, resG)(c4)\n",
    "    \n",
    "    m4 = MaxPool3D((2,2,2))(rev4)\n",
    "    c5 = Conv3D(256, kernel_size=(1,1,1), strides=(1,1,1),padding='same')(m4)\n",
    "    \n",
    "    resF = ResidualInner(filters=128, strides=1)\n",
    "    resG = ResidualInner(filters=128, strides=1)\n",
    "    rev5 = ReversibleLayer(resF, resG)(c5)\n",
    "    \n",
    "    resF = ResidualInner(filters=128, strides=1)\n",
    "    resG = ResidualInner(filters=128, strides=1)\n",
    "    rev6 = ReversibleLayer(resF, resG)(rev5)\n",
    "    \n",
    "    upConv1 = Conv3D(128, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(rev6)\n",
    "    upSample1 = UpSampling3D(2)(upConv1)\n",
    "    \n",
    "    rev7 = concatenate([rev4, upSample1])\n",
    "    \n",
    "    resF = ResidualInner(filters=128, strides=1)\n",
    "    resG = ResidualInner(filters=128, strides=1)\n",
    "    rev7 = ReversibleLayer(resF, resG)(rev7)\n",
    "    \n",
    "    upConv2 = Conv3D(64, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(rev7)\n",
    "    upSample2 = UpSampling3D(2)(upConv2)\n",
    "    \n",
    "    rev8 = concatenate([rev3, upSample2])\n",
    "    \n",
    "    resF = ResidualInner(filters=64, strides=1)\n",
    "    resG = ResidualInner(filters=64, strides=1)\n",
    "    rev8 = ReversibleLayer(resF, resG)(rev8)\n",
    "    \n",
    "    upConv3 = Conv3D(32, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(rev8)\n",
    "    upSample3 = UpSampling3D(2)(upConv3)\n",
    "    \n",
    "    rev9 = concatenate([rev2, upSample3])\n",
    "    \n",
    "    resF = ResidualInner(filters=32, strides=1)\n",
    "    resG = ResidualInner(filters=32, strides=1)\n",
    "    rev9 = ReversibleLayer(resF, resG)(rev9)\n",
    "    \n",
    "    upConv4 = Conv3D(16, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(rev9)\n",
    "    upSample4 = UpSampling3D(2)(upConv4)\n",
    "    \n",
    "    rev10 = concatenate([rev1, upSample4])\n",
    "    \n",
    "    resF = ResidualInner(filters=16, strides=1)\n",
    "    resG = ResidualInner(filters=16, strides=1)\n",
    "    rev10 = ReversibleLayer(resF, resG)(rev10)\n",
    "    \n",
    "    final_conv = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(rev10)\n",
    "    output = Activation('softmax')(final_conv)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=output)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "improved_model = unet_3d(input_layer) \n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = False # Whether to save the model after training\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "improved_model.compile(optimizer=keras.optimizers.SGD(learning_rate=LR), loss=focal_tversky_loss, metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "improved_model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[callbacks, WandbCallback()])\n",
    "if SAVE_MODEL:\n",
    "  improved_model.save(\"improved_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 0 is just an index of a 3D scan\n",
    "# Next 0 is X in tuple X, y\n",
    "# Next 0 is from the batch. We only have one, so we pick the first.\n",
    "img1 = training_generator.__getitem__(0)[0][0]\n",
    "\n",
    "# Get the ground truth of the training image above (i.e. y from tuple (X, y))\n",
    "img2 = training_generator.__getitem__(0)[1][0]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "# [70,:,:,0] is slice 70. 0 is the FLAIR channel.\n",
    "plt.imshow(img1[70,:,:,0])\n",
    "plt.show()\n",
    "\n",
    "# Same slice as above, 1 is the necrotic tumor core\n",
    "plt.imshow(img2[70, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions? Maybe we should do an example (or a few) where we use the trained model to predict segmentation masks on data we have not trained on (i.e. the two brain scans that were included in the data set but not in the training-data file**\n",
    "\n",
    "**Something like this:** https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/ **(scroll down to \"predictions\")**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4270e3f338dc97884e39dfa435881d633bb85d0979a79226f74580c90b39f6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
