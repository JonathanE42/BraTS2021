{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 08:39:21.965178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-06 08:39:22.309501: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-06 08:39:23.098508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/viktorsalling/miniconda3/lib/\n",
      "2022-12-06 08:39:23.098629: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/viktorsalling/miniconda3/lib/\n",
      "2022-12-06 08:39:23.098637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage \n",
    "from skimage.transform import rotate\n",
    "import keras\n",
    "import random\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import cv2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unpack data** \n",
    "\n",
    "*NB: Size is 13.5 GB, code is commented out to prevent accidental unpacking*\n",
    "\n",
    "**TEST THIS BEFORE HAND IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tarfile\n",
    "#file = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')\n",
    "\n",
    "#file.extractall(os.getenv('TRAIN-PATH'))\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics and loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "        =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    axis = (0,1,2,3)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "# Loss functions here: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook\n",
    "\n",
    "ALPHA = 0.7\n",
    "BETA = 0.3\n",
    "GAMMA = 1\n",
    "\n",
    "def focal_tversky_loss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):\n",
    "    \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))\n",
    "               \n",
    "        Tversky = (TP + smooth) / (TP + beta*FP + alpha*FN + smooth)  \n",
    "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
    "        \n",
    "        return FocalTversky\n",
    "\n",
    "\n",
    "\n",
    "# define per class evaluation of dice coef\n",
    "# inspired by https://github.com/keras-team/keras/issues/9395\n",
    "def dice_coef_healthy(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,0] * y_pred[0,:,:,:,0]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,0])) + K.sum(K.square(y_pred[0,:,:,:,0])) + epsilon)\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,1] * y_pred[0,:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,1])) + K.sum(K.square(y_pred[0,:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,2] * y_pred[0,:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,2])) + K.sum(K.square(y_pred[0,:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,3] * y_pred[0,:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,3])) + K.sum(K.square(y_pred[0,:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=120 # Originally 240x240, we reduce this to reduce memory usage\n",
    "SLICES=128 # Originally 155, reduced for same reason. Must be a power of 2 (or at least divisible by 2, 3 times)\n",
    "SLICES_START=13 # We skip the first (and the last) few slices as they should contain less information\n",
    "BATCH_SIZE=1\n",
    "CHANNELS=4\n",
    "DATA_AUG=False # Enables data augmentation\n",
    "DATA_AUG_FACTOR=0 # If we have n data elements, we will have DATA_AUG_FACTOR*n data elements to train on\n",
    "\n",
    "TRAIN_DATASET_PATH = os.getenv('TRAIN-PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomBrightness(X, y):\n",
    "  X = tf.image.stateless_random_brightness(X, 0.2, seed=(1,2)).numpy()\n",
    "  y = tf.image.stateless_random_brightness(y, 0.2, seed=(1,2)).numpy()\n",
    "  return X, y\n",
    "\n",
    "def RandomRotate(X, y):\n",
    "    r = random.randint(0,3)\n",
    "    # rotate by 90 degrees times random r\n",
    "    X = np.rot90(X, k=r)\n",
    "    y = np.rot90(y, k=r)\n",
    "    return X, y \n",
    "    \n",
    "def AugmentData(X, y):\n",
    "  X, y = RandomRotate(X, y)\n",
    "  X, y = RandomBrightness(X, y)\n",
    "  return X, y\n",
    "  \n",
    "data_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "data_ids = pathListIntoIds(data_directories); \n",
    "\n",
    "    \n",
    "train_and_test_ids, val_ids = train_test_split(data_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(train_and_test_ids,test_size=0.2)\n",
    "\n",
    "\n",
    "keras = tf.compat.v1.keras\n",
    "Sequence = keras.utils.Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = BATCH_SIZE, n_channels = CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*SLICES, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');\n",
    "            ce = nib.load(data_path).get_fdata()   \n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1.nii.gz');\n",
    "            t1 = nib.load(data_path).get_fdata()       \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii.gz');\n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(SLICES):\n",
    "                X[j+(SLICES*c),:,:,0] = cv2.resize(flair[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,1] = cv2.resize(ce[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,2] = cv2.resize(t1[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,3] = cv2.resize(t2[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))                \n",
    "                \n",
    "                y[j +SLICES*c,:,:] = cv2.resize(seg[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        if DATA_AUG: X, y = AugmentData(X, y)\n",
    "\n",
    "        X = X.reshape(1,SLICES,IMG_SIZE,IMG_SIZE, CHANNELS)\n",
    "        y = y.reshape(1,SLICES,IMG_SIZE,IMG_SIZE)\n",
    "        # Generate masks\n",
    "        #y[y==4] = 3;\n",
    "        y = tf.one_hot(y, 4);\n",
    "\n",
    "        # Avoid dividing by zero - return early\n",
    "        if np.max(X) == 0.0:\n",
    "          return np.zeros(X.shape), y\n",
    "\n",
    "        return X/np.max(X), y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids*DATA_AUG_FACTOR) if DATA_AUG else DataGenerator(train_ids) \n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c2)\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = UpSampling3D(2)(c11)\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = UpSampling3D(2)(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = UpSampling3D(2)(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "model = unet_3d(input_layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test (baseline) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = False # Whether to save the model after training\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=LR), loss=\"categorical_crossentropy\", metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "model.summary()\n",
    "model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[WandbCallback()])\n",
    "if SAVE_MODEL:\n",
    "  model.save(\"baseline_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruct model and test it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"baseline_model.h5\", custom_objects={\"dice_coef\":dice_coef, \n",
    "                                                                                \"precision\":precision, \n",
    "                                                                                \"sensitivity\":sensitivity, \n",
    "                                                                                \"specificity\":specificity,\n",
    "                                                                                \"dice_coef_necrotic\":dice_coef_necrotic, \n",
    "                                                                                \"dice_coef_edema\":dice_coef_edema, \n",
    "                                                                                \"dice_coef_enhancing\":dice_coef_enhancing,\n",
    "                                                                                \"dice_coef_healthy\": dice_coef_healthy})\n",
    "reconstructed_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Callbacks for improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,\n",
    "                               patience=10, verbose=1, mode='auto'),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 120, 1  0           []                               \n",
      "                                20, 4)]                                                           \n",
      "                                                                                                  \n",
      " conv3d_18 (Conv3D)             (None, 128, 120, 12  872         ['input_2[0][0]']                \n",
      "                                0, 8)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 128, 120, 12  32         ['conv3d_18[0][0]']              \n",
      " ormalization)                  0, 8)                                                             \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_14[0][0]'] \n",
      "                                0, 8)                                                             \n",
      "                                                                                                  \n",
      " conv3d_19 (Conv3D)             (None, 128, 120, 12  3472        ['activation_15[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 128, 120, 12  64         ['conv3d_19[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_15[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_20 (Conv3D)             (None, 64, 60, 60,   6928        ['activation_16[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_21 (Conv3D)             (None, 64, 60, 60,   6928        ['conv3d_20[0][0]']              \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 64, 60, 60,   64         ['conv3d_21[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_16[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_22 (Conv3D)             (None, 64, 60, 60,   13856       ['activation_17[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 64, 60, 60,   128        ['conv3d_22[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_17[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_23 (Conv3D)             (None, 32, 30, 30,   27680       ['activation_18[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_24 (Conv3D)             (None, 32, 30, 30,   27680       ['conv3d_23[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 30, 30,   128        ['conv3d_24[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_18[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_25 (Conv3D)             (None, 32, 30, 30,   55360       ['activation_19[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 30, 30,   256        ['conv3d_25[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_19[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_26 (Conv3D)             (None, 16, 15, 15,   110656      ['activation_20[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_27 (Conv3D)             (None, 16, 15, 15,   110656      ['conv3d_26[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 15, 15,   256        ['conv3d_27[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 15, 15,   0           ['batch_normalization_20[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_28 (Conv3D)             (None, 16, 15, 15,   221312      ['activation_21[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 15, 15,   512        ['conv3d_28[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 15, 15,   0           ['batch_normalization_21[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_3 (Conv3DTran  (None, 32, 30, 30,   131200     ['activation_22[0][0]']          \n",
      " spose)                         128)                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 32, 30, 30,   0           ['activation_20[0][0]',          \n",
      "                                192)                              'conv3d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_29 (Conv3D)             (None, 32, 30, 30,   331840      ['concatenate_3[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 32, 30, 30,   256        ['conv3d_29[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_22[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_30 (Conv3D)             (None, 32, 30, 30,   110656      ['activation_23[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 32, 30, 30,   256        ['conv3d_30[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_23[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_4 (Conv3DTran  (None, 64, 60, 60,   32832      ['activation_24[0][0]']          \n",
      " spose)                         64)                                                               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 60, 60,   0           ['activation_18[0][0]',          \n",
      "                                96)                               'conv3d_transpose_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_31 (Conv3D)             (None, 64, 60, 60,   82976       ['concatenate_4[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 64, 60, 60,   128        ['conv3d_31[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_24[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_32 (Conv3D)             (None, 64, 60, 60,   27680       ['activation_25[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 64, 60, 60,   128        ['conv3d_32[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_25[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_5 (Conv3DTran  (None, 128, 120, 12  8224       ['activation_26[0][0]']          \n",
      " spose)                         0, 32)                                                            \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128, 120, 12  0           ['activation_16[0][0]',          \n",
      "                                0, 48)                            'conv3d_transpose_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_33 (Conv3D)             (None, 128, 120, 12  20752       ['concatenate_5[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 128, 120, 12  64         ['conv3d_33[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_26[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_34 (Conv3D)             (None, 128, 120, 12  6928        ['activation_27[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 128, 120, 12  64         ['conv3d_34[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_27[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_35 (Conv3D)             (None, 128, 120, 12  68          ['activation_28[0][0]']          \n",
      "                                0, 4)                                                             \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 128, 120, 12  0           ['conv3d_35[0][0]']              \n",
      "                                0, 4)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,340,892\n",
      "Trainable params: 1,339,724\n",
      "Non-trainable params: 1,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = Conv3D(16, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c2) # Use convolution instead of max pool\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = Conv3D(32, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = Conv3DTranspose(128, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c11) # Use Transpose instead of UpSampling, kernel size should be divisble by stride\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = Conv3DTranspose(64, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = Conv3DTranspose(32, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "improved_model = unet_3d(input_layer) \n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:21jawmp3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁██</td></tr><tr><td>dice_coef</td><td>▁▇█</td></tr><tr><td>dice_coef_edema</td><td>▁▇█</td></tr><tr><td>dice_coef_enhancing</td><td>█▂▁</td></tr><tr><td>dice_coef_healthy</td><td>▁██</td></tr><tr><td>dice_coef_necrotic</td><td>█▃▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▁▁</td></tr><tr><td>lr</td><td>▁▁▁</td></tr><tr><td>mean_io_u</td><td>▁▂█</td></tr><tr><td>precision</td><td>▁██</td></tr><tr><td>sensitivity</td><td>▁██</td></tr><tr><td>specificity</td><td>▁▇█</td></tr><tr><td>val_accuracy</td><td>█▃▁</td></tr><tr><td>val_dice_coef</td><td>▁▅█</td></tr><tr><td>val_dice_coef_edema</td><td>▁█▆</td></tr><tr><td>val_dice_coef_enhancing</td><td>█▁▄</td></tr><tr><td>val_dice_coef_healthy</td><td>█▃▁</td></tr><tr><td>val_dice_coef_necrotic</td><td>▁▁█</td></tr><tr><td>val_loss</td><td>▁▃█</td></tr><tr><td>val_mean_io_u</td><td>██▁</td></tr><tr><td>val_precision</td><td>█▃▁</td></tr><tr><td>val_sensitivity</td><td>█▃▁</td></tr><tr><td>val_specificity</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99206</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.02837</td></tr><tr><td>dice_coef</td><td>0.39931</td></tr><tr><td>dice_coef_edema</td><td>0.59188</td></tr><tr><td>dice_coef_enhancing</td><td>0.0004</td></tr><tr><td>dice_coef_healthy</td><td>0.99791</td></tr><tr><td>dice_coef_necrotic</td><td>0.00695</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>0.00712</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>mean_io_u</td><td>0.37615</td></tr><tr><td>precision</td><td>0.99152</td></tr><tr><td>sensitivity</td><td>0.99375</td></tr><tr><td>specificity</td><td>0.99718</td></tr><tr><td>val_accuracy</td><td>0.96994</td></tr><tr><td>val_dice_coef</td><td>0.31556</td></tr><tr><td>val_dice_coef_edema</td><td>0.23267</td></tr><tr><td>val_dice_coef_enhancing</td><td>0.00041</td></tr><tr><td>val_dice_coef_healthy</td><td>0.98524</td></tr><tr><td>val_dice_coef_necrotic</td><td>0.04383</td></tr><tr><td>val_loss</td><td>0.02965</td></tr><tr><td>val_mean_io_u</td><td>0.37499</td></tr><tr><td>val_precision</td><td>0.96912</td></tr><tr><td>val_sensitivity</td><td>0.97111</td></tr><tr><td>val_specificity</td><td>0.98972</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dauntless-frog-153</strong>: <a href=\"https://wandb.ai/vj-dl/BraTS2021/runs/21jawmp3\" target=\"_blank\">https://wandb.ai/vj-dl/BraTS2021/runs/21jawmp3</a><br/>Synced 6 W&B file(s), 1 media file(s), 4 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221206_084000-21jawmp3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:21jawmp3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/vj-dl/BraTS2021/runs/20mcx671\" target=\"_blank\">pious-sunset-154</a></strong> to <a href=\"https://wandb.ai/vj-dl/BraTS2021\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9827 - mean_io_u_1: 0.3753 - dice_coef: 0.3795 - precision: 0.9866 - sensitivity: 0.9725 - specificity: 0.9963 - dice_coef_necrotic: 0.1029 - dice_coef_edema: 0.4130 - dice_coef_enhancing: 0.0183 - dice_coef_healthy: 0.9839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 708s 880ms/step - loss: 0.0708 - accuracy: 0.9827 - mean_io_u_1: 0.3753 - dice_coef: 0.3795 - precision: 0.9866 - sensitivity: 0.9725 - specificity: 0.9963 - dice_coef_necrotic: 0.1029 - dice_coef_edema: 0.4130 - dice_coef_enhancing: 0.0183 - dice_coef_healthy: 0.9839 - val_loss: 0.0462 - val_accuracy: 0.9579 - val_mean_io_u_1: 0.3754 - val_dice_coef: 0.3093 - val_precision: 0.9574 - val_sensitivity: 0.9589 - val_specificity: 0.9859 - val_dice_coef_necrotic: 0.0128 - val_dice_coef_edema: 0.2406 - val_dice_coef_enhancing: 0.0047 - val_dice_coef_healthy: 0.9790 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9914 - mean_io_u_1: 0.3754 - dice_coef: 0.3913 - precision: 0.9908 - sensitivity: 0.9930 - specificity: 0.9969 - dice_coef_necrotic: 0.0136 - dice_coef_edema: 0.5517 - dice_coef_enhancing: 0.0025 - dice_coef_healthy: 0.9975"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 707s 884ms/step - loss: 0.0094 - accuracy: 0.9914 - mean_io_u_1: 0.3754 - dice_coef: 0.3913 - precision: 0.9908 - sensitivity: 0.9930 - specificity: 0.9969 - dice_coef_necrotic: 0.0136 - dice_coef_edema: 0.5517 - dice_coef_enhancing: 0.0025 - dice_coef_healthy: 0.9975 - val_loss: 0.0264 - val_accuracy: 0.9741 - val_mean_io_u_1: 0.3757 - val_dice_coef: 0.2980 - val_precision: 0.9730 - val_sensitivity: 0.9751 - val_specificity: 0.9910 - val_dice_coef_necrotic: 0.0022 - val_dice_coef_edema: 0.2017 - val_dice_coef_enhancing: 7.2380e-04 - val_dice_coef_healthy: 0.9872 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 700s 875ms/step - loss: 0.0077 - accuracy: 0.9919 - mean_io_u_1: 0.3755 - dice_coef: 0.3956 - precision: 0.9914 - sensitivity: 0.9936 - specificity: 0.9971 - dice_coef_necrotic: 0.0050 - dice_coef_edema: 0.5786 - dice_coef_enhancing: 9.4858e-04 - dice_coef_healthy: 0.9978 - val_loss: 0.0294 - val_accuracy: 0.9706 - val_mean_io_u_1: 0.3760 - val_dice_coef: 0.3093 - val_precision: 0.9697 - val_sensitivity: 0.9717 - val_specificity: 0.9899 - val_dice_coef_necrotic: 0.0083 - val_dice_coef_edema: 0.2429 - val_dice_coef_enhancing: 4.6402e-04 - val_dice_coef_healthy: 0.9854 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9922 - mean_io_u_1: 0.3757 - dice_coef: 0.3998 - precision: 0.9917 - sensitivity: 0.9939 - specificity: 0.9972 - dice_coef_necrotic: 0.0031 - dice_coef_edema: 0.5976 - dice_coef_enhancing: 5.3911e-04 - dice_coef_healthy: 0.9980\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "800/800 [==============================] - 705s 881ms/step - loss: 0.0070 - accuracy: 0.9922 - mean_io_u_1: 0.3757 - dice_coef: 0.3998 - precision: 0.9917 - sensitivity: 0.9939 - specificity: 0.9972 - dice_coef_necrotic: 0.0031 - dice_coef_edema: 0.5976 - dice_coef_enhancing: 5.3911e-04 - dice_coef_healthy: 0.9980 - val_loss: 0.0283 - val_accuracy: 0.9714 - val_mean_io_u_1: 0.3767 - val_dice_coef: 0.3101 - val_precision: 0.9704 - val_sensitivity: 0.9725 - val_specificity: 0.9902 - val_dice_coef_necrotic: 4.5066e-04 - val_dice_coef_edema: 0.2537 - val_dice_coef_enhancing: 1.5396e-04 - val_dice_coef_healthy: 0.9859 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 703s 878ms/step - loss: 0.0065 - accuracy: 0.9925 - mean_io_u_1: 0.3762 - dice_coef: 0.4058 - precision: 0.9921 - sensitivity: 0.9943 - specificity: 0.9974 - dice_coef_necrotic: 0.0019 - dice_coef_edema: 0.6226 - dice_coef_enhancing: 3.2574e-04 - dice_coef_healthy: 0.9983 - val_loss: 0.0273 - val_accuracy: 0.9723 - val_mean_io_u_1: 0.3799 - val_dice_coef: 0.3064 - val_precision: 0.9714 - val_sensitivity: 0.9735 - val_specificity: 0.9905 - val_dice_coef_necrotic: 0.0014 - val_dice_coef_edema: 0.2373 - val_dice_coef_enhancing: 6.0398e-04 - val_dice_coef_healthy: 0.9864 - lr: 2.0000e-04\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9926 - mean_io_u_1: 0.3762 - dice_coef: 0.4066 - precision: 0.9922 - sensitivity: 0.9944 - specificity: 0.9974 - dice_coef_necrotic: 0.0021 - dice_coef_edema: 0.6255 - dice_coef_enhancing: 3.5653e-04 - dice_coef_healthy: 0.9983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221206_091810-20mcx671/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 707s 883ms/step - loss: 0.0064 - accuracy: 0.9926 - mean_io_u_1: 0.3762 - dice_coef: 0.4066 - precision: 0.9922 - sensitivity: 0.9944 - specificity: 0.9974 - dice_coef_necrotic: 0.0021 - dice_coef_edema: 0.6255 - dice_coef_enhancing: 3.5653e-04 - dice_coef_healthy: 0.9983 - val_loss: 0.0253 - val_accuracy: 0.9744 - val_mean_io_u_1: 0.4068 - val_dice_coef: 0.3067 - val_precision: 0.9734 - val_sensitivity: 0.9755 - val_specificity: 0.9911 - val_dice_coef_necrotic: 5.1466e-04 - val_dice_coef_edema: 0.2386 - val_dice_coef_enhancing: 2.7373e-04 - val_dice_coef_healthy: 0.9874 - lr: 2.0000e-04\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 705s 881ms/step - loss: 0.0064 - accuracy: 0.9926 - mean_io_u_1: 0.3766 - dice_coef: 0.4068 - precision: 0.9922 - sensitivity: 0.9944 - specificity: 0.9974 - dice_coef_necrotic: 0.0019 - dice_coef_edema: 0.6266 - dice_coef_enhancing: 3.2843e-04 - dice_coef_healthy: 0.9983 - val_loss: 0.0290 - val_accuracy: 0.9706 - val_mean_io_u_1: 0.4022 - val_dice_coef: 0.3065 - val_precision: 0.9696 - val_sensitivity: 0.9717 - val_specificity: 0.9899 - val_dice_coef_necrotic: 5.5862e-04 - val_dice_coef_edema: 0.2398 - val_dice_coef_enhancing: 2.6533e-04 - val_dice_coef_healthy: 0.9854 - lr: 2.0000e-04\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9927 - mean_io_u_1: 0.3770 - dice_coef: 0.4078 - precision: 0.9923 - sensitivity: 0.9945 - specificity: 0.9974 - dice_coef_necrotic: 0.0022 - dice_coef_edema: 0.6302 - dice_coef_enhancing: 2.8049e-04 - dice_coef_healthy: 0.9984\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "800/800 [==============================] - 713s 891ms/step - loss: 0.0063 - accuracy: 0.9927 - mean_io_u_1: 0.3770 - dice_coef: 0.4078 - precision: 0.9923 - sensitivity: 0.9945 - specificity: 0.9974 - dice_coef_necrotic: 0.0022 - dice_coef_edema: 0.6302 - dice_coef_enhancing: 2.8049e-04 - dice_coef_healthy: 0.9984 - val_loss: 0.0277 - val_accuracy: 0.9719 - val_mean_io_u_1: 0.4149 - val_dice_coef: 0.3089 - val_precision: 0.9710 - val_sensitivity: 0.9730 - val_specificity: 0.9903 - val_dice_coef_necrotic: 0.0024 - val_dice_coef_edema: 0.2464 - val_dice_coef_enhancing: 5.9266e-04 - val_dice_coef_healthy: 0.9861 - lr: 2.0000e-04\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 712s 890ms/step - loss: 0.0061 - accuracy: 0.9928 - mean_io_u_1: 0.3768 - dice_coef: 0.4184 - precision: 0.9925 - sensitivity: 0.9946 - specificity: 0.9975 - dice_coef_necrotic: 0.0341 - dice_coef_edema: 0.6402 - dice_coef_enhancing: 8.0250e-04 - dice_coef_healthy: 0.9985 - val_loss: 0.0279 - val_accuracy: 0.9717 - val_mean_io_u_1: 0.4070 - val_dice_coef: 0.3221 - val_precision: 0.9708 - val_sensitivity: 0.9728 - val_specificity: 0.9903 - val_dice_coef_necrotic: 0.0529 - val_dice_coef_edema: 0.2483 - val_dice_coef_enhancing: 0.0010 - val_dice_coef_healthy: 0.9861 - lr: 4.0000e-05\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9930 - mean_io_u_1: 0.3770 - dice_coef: 0.4466 - precision: 0.9927 - sensitivity: 0.9949 - specificity: 0.9976 - dice_coef_necrotic: 0.1360 - dice_coef_edema: 0.6513 - dice_coef_enhancing: 4.8314e-04 - dice_coef_healthy: 0.9985\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "800/800 [==============================] - 708s 885ms/step - loss: 0.0059 - accuracy: 0.9930 - mean_io_u_1: 0.3770 - dice_coef: 0.4466 - precision: 0.9927 - sensitivity: 0.9949 - specificity: 0.9976 - dice_coef_necrotic: 0.1360 - dice_coef_edema: 0.6513 - dice_coef_enhancing: 4.8314e-04 - dice_coef_healthy: 0.9985 - val_loss: 0.0291 - val_accuracy: 0.9704 - val_mean_io_u_1: 0.4090 - val_dice_coef: 0.3269 - val_precision: 0.9696 - val_sensitivity: 0.9716 - val_specificity: 0.9899 - val_dice_coef_necrotic: 0.0806 - val_dice_coef_edema: 0.2411 - val_dice_coef_enhancing: 3.6915e-04 - val_dice_coef_healthy: 0.9855 - lr: 4.0000e-05\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 711s 888ms/step - loss: 0.0058 - accuracy: 0.9931 - mean_io_u_1: 0.3770 - dice_coef: 0.4506 - precision: 0.9928 - sensitivity: 0.9950 - specificity: 0.9976 - dice_coef_necrotic: 0.1499 - dice_coef_edema: 0.6536 - dice_coef_enhancing: 2.4377e-04 - dice_coef_healthy: 0.9986 - val_loss: 0.0293 - val_accuracy: 0.9703 - val_mean_io_u_1: 0.4106 - val_dice_coef: 0.3288 - val_precision: 0.9695 - val_sensitivity: 0.9715 - val_specificity: 0.9898 - val_dice_coef_necrotic: 0.1122 - val_dice_coef_edema: 0.2168 - val_dice_coef_enhancing: 4.4469e-04 - val_dice_coef_healthy: 0.9856 - lr: 8.0000e-06\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9931 - mean_io_u_1: 0.3771 - dice_coef: 0.4536 - precision: 0.9928 - sensitivity: 0.9950 - specificity: 0.9976 - dice_coef_necrotic: 0.1609 - dice_coef_edema: 0.6548 - dice_coef_enhancing: 2.4565e-04 - dice_coef_healthy: 0.9986\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "800/800 [==============================] - 707s 884ms/step - loss: 0.0058 - accuracy: 0.9931 - mean_io_u_1: 0.3771 - dice_coef: 0.4536 - precision: 0.9928 - sensitivity: 0.9950 - specificity: 0.9976 - dice_coef_necrotic: 0.1609 - dice_coef_edema: 0.6548 - dice_coef_enhancing: 2.4565e-04 - dice_coef_healthy: 0.9986 - val_loss: 0.0306 - val_accuracy: 0.9689 - val_mean_io_u_1: 0.4060 - val_dice_coef: 0.3316 - val_precision: 0.9681 - val_sensitivity: 0.9701 - val_specificity: 0.9894 - val_dice_coef_necrotic: 0.1097 - val_dice_coef_edema: 0.2314 - val_dice_coef_enhancing: 4.7588e-04 - val_dice_coef_healthy: 0.9848 - lr: 8.0000e-06\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 705s 880ms/step - loss: 0.0058 - accuracy: 0.9931 - mean_io_u_1: 0.3771 - dice_coef: 0.4534 - precision: 0.9928 - sensitivity: 0.9950 - specificity: 0.9976 - dice_coef_necrotic: 0.1595 - dice_coef_edema: 0.6553 - dice_coef_enhancing: 2.2032e-04 - dice_coef_healthy: 0.9986 - val_loss: 0.0303 - val_accuracy: 0.9692 - val_mean_io_u_1: 0.4066 - val_dice_coef: 0.3313 - val_precision: 0.9684 - val_sensitivity: 0.9704 - val_specificity: 0.9895 - val_dice_coef_necrotic: 0.1112 - val_dice_coef_edema: 0.2285 - val_dice_coef_enhancing: 4.8235e-04 - val_dice_coef_healthy: 0.9850 - lr: 1.6000e-06\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9931 - mean_io_u_1: 0.3771 - dice_coef: 0.4567 - precision: 0.9928 - sensitivity: 0.9950 - specificity: 0.9976 - dice_coef_necrotic: 0.1714 - dice_coef_edema: 0.6566 - dice_coef_enhancing: 2.3346e-04 - dice_coef_healthy: 0.9986\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "800/800 [==============================] - 704s 880ms/step - loss: 0.0058 - accuracy: 0.9931 - mean_io_u_1: 0.3771 - dice_coef: 0.4567 - precision: 0.9928 - sensitivity: 0.9950 - specificity: 0.9976 - dice_coef_necrotic: 0.1714 - dice_coef_edema: 0.6566 - dice_coef_enhancing: 2.3346e-04 - dice_coef_healthy: 0.9986 - val_loss: 0.0298 - val_accuracy: 0.9697 - val_mean_io_u_1: 0.4060 - val_dice_coef: 0.3324 - val_precision: 0.9689 - val_sensitivity: 0.9709 - val_specificity: 0.9897 - val_dice_coef_necrotic: 0.1050 - val_dice_coef_edema: 0.2391 - val_dice_coef_enhancing: 3.7547e-04 - val_dice_coef_healthy: 0.9852 - lr: 1.6000e-06\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 703s 879ms/step - loss: 0.0058 - accuracy: 0.9931 - mean_io_u_1: 0.3771 - dice_coef: 0.4540 - precision: 0.9928 - sensitivity: 0.9950 - specificity: 0.9976 - dice_coef_necrotic: 0.1614 - dice_coef_edema: 0.6557 - dice_coef_enhancing: 2.1308e-04 - dice_coef_healthy: 0.9986 - val_loss: 0.0327 - val_accuracy: 0.9669 - val_mean_io_u_1: 0.4068 - val_dice_coef: 0.3365 - val_precision: 0.9661 - val_sensitivity: 0.9681 - val_specificity: 0.9887 - val_dice_coef_necrotic: 0.1093 - val_dice_coef_edema: 0.2527 - val_dice_coef_enhancing: 3.1132e-04 - val_dice_coef_healthy: 0.9838 - lr: 1.0000e-06\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 710s 887ms/step - loss: 0.0058 - accuracy: 0.9931 - mean_io_u_1: 0.3771 - dice_coef: 0.4547 - precision: 0.9928 - sensitivity: 0.9950 - specificity: 0.9976 - dice_coef_necrotic: 0.1640 - dice_coef_edema: 0.6559 - dice_coef_enhancing: 2.1364e-04 - dice_coef_healthy: 0.9986 - val_loss: 0.0316 - val_accuracy: 0.9679 - val_mean_io_u_1: 0.4061 - val_dice_coef: 0.3339 - val_precision: 0.9671 - val_sensitivity: 0.9691 - val_specificity: 0.9891 - val_dice_coef_necrotic: 0.1110 - val_dice_coef_edema: 0.2400 - val_dice_coef_enhancing: 3.6402e-04 - val_dice_coef_healthy: 0.9843 - lr: 1.0000e-06\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = False # Whether to save the model after training\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "improved_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=LR), loss=focal_tversky_loss, metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "improved_model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[callbacks, WandbCallback()])\n",
    "if SAVE_MODEL:\n",
    "  improved_model.save(\"improved_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 95s 470ms/step - loss: 0.0377 - accuracy: 0.9618 - mean_io_u_1: 0.4048 - dice_coef: 0.3371 - precision: 0.9609 - sensitivity: 0.9630 - specificity: 0.9870 - dice_coef_necrotic: 0.1103 - dice_coef_edema: 0.2567 - dice_coef_enhancing: 3.0945e-04 - dice_coef_healthy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.037746381014585495,\n",
       " 0.961807906627655,\n",
       " 0.40481796860694885,\n",
       " 0.33710435032844543,\n",
       " 0.9609484076499939,\n",
       " 0.9630271196365356,\n",
       " 0.9869999885559082,\n",
       " 0.11027680337429047,\n",
       " 0.2567276358604431,\n",
       " 0.00030945430626161397,\n",
       " 0.9810264110565186]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 0 is just an index of a 3D scan\n",
    "# Next 0 is X in tuple X, y\n",
    "# Next 0 is from the batch. We only have one, so we pick the first.\n",
    "img1 = training_generator.__getitem__(0)[0][0]\n",
    "\n",
    "# Get the ground truth of the training image above (i.e. y from tuple (X, y))\n",
    "img2 = training_generator.__getitem__(0)[1][0]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "# [70,:,:,0] is slice 70. 0 is the FLAIR channel.\n",
    "plt.imshow(img1[70,:,:,0])\n",
    "plt.show()\n",
    "\n",
    "# Same slice as above, 1 is the necrotic tumor core\n",
    "plt.imshow(img2[70, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions? Maybe we should do an example (or a few) where we use the trained model to predict segmentation masks on data we have not trained on (i.e. the two brain scans that were included in the data set but not in the training-data file**\n",
    "\n",
    "**Something like this:** https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/ **(scroll down to \"predictions\")**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4270e3f338dc97884e39dfa435881d633bb85d0979a79226f74580c90b39f6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
