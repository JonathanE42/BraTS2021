{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage \n",
    "from skimage.transform import rotate\n",
    "#from datetime import datetime\n",
    "#import seaborn as sns\n",
    "import keras\n",
    "import random\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import cv2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unpack data** \n",
    "\n",
    "*NB: Size is 13.5 GB, code is commented out to prevent accidental unpacking*\n",
    "\n",
    "**TEST THIS BEFORE HAND IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tarfile\n",
    "#file = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')\n",
    "\n",
    "#file.extractall(os.getenv('TRAIN-PATH'))\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics and loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "        =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    axis = (0,1,2,3)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "# Loss functions here: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch/notebook\n",
    "\n",
    "ALPHA = 0.7\n",
    "BETA = 0.3\n",
    "GAMMA = 1\n",
    "\n",
    "def focal_tversky_loss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):\n",
    "    \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))\n",
    "               \n",
    "        Tversky = (TP + smooth) / (TP + beta*FP + alpha*FN + smooth)  \n",
    "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
    "        \n",
    "        return FocalTversky\n",
    "\n",
    "\n",
    "\n",
    "# define per class evaluation of dice coef\n",
    "# inspired by https://github.com/keras-team/keras/issues/9395\n",
    "def dice_coef_healthy(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,0] * y_pred[0,:,:,:,0]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,0])) + K.sum(K.square(y_pred[0,:,:,:,0])) + epsilon)\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,1] * y_pred[0,:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,1])) + K.sum(K.square(y_pred[0,:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,2] * y_pred[0,:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,2])) + K.sum(K.square(y_pred[0,:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[0,:,:,:,3] * y_pred[0,:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[0,:,:,:,3])) + K.sum(K.square(y_pred[0,:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=120 # Originally 240x240, we reduce this to reduce memory usage\n",
    "SLICES=128 # Originally 155, reduced for same reason. Must be a power of 2 (or at least divisible by 2, 3 times)\n",
    "SLICES_START=13 # We skip the first (and the last) few slices as they should contain less information\n",
    "BATCH_SIZE=1\n",
    "CHANNELS=4\n",
    "DATA_AUG=False # Enables data augmentation\n",
    "DATA_AUG_FACTOR=0 # If we have n data elements, we will have DATA_AUG_FACTOR*n data elements to train on\n",
    "\n",
    "TRAIN_DATASET_PATH = os.getenv('TRAIN-PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomBrightness(X, y):\n",
    "  X = tf.image.stateless_random_brightness(X, 0.2, seed=(1,2)).numpy()\n",
    "  y = tf.image.stateless_random_brightness(y, 0.2, seed=(1,2)).numpy()\n",
    "  return X, y\n",
    "\n",
    "def RandomRotate(X, y):\n",
    "    r = random.randint(0,3)\n",
    "    # rotate by 90 degrees times random r\n",
    "    X = np.rot90(X, k=r)\n",
    "    y = np.rot90(y, k=r)\n",
    "    return X, y \n",
    "    \n",
    "def AugmentData(X, y):\n",
    "  X, y = RandomRotate(X, y)\n",
    "  X, y = RandomBrightness(X, y)\n",
    "  return X, y\n",
    "  \n",
    "data_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "data_ids = pathListIntoIds(data_directories); \n",
    "\n",
    "    \n",
    "train_and_test_ids, val_ids = train_test_split(data_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(train_and_test_ids,test_size=0.2)\n",
    "\n",
    "\n",
    "keras = tf.compat.v1.keras\n",
    "Sequence = keras.utils.Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = BATCH_SIZE, n_channels = CHANNELS, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*SLICES, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n",
    "            flair = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');\n",
    "            ce = nib.load(data_path).get_fdata()   \n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_t1.nii.gz');\n",
    "            t1 = nib.load(data_path).get_fdata()       \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t2.nii.gz');\n",
    "            t2 = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(SLICES):\n",
    "                X[j+(SLICES*c),:,:,0] = cv2.resize(flair[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,1] = cv2.resize(ce[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,2] = cv2.resize(t1[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "                X[j+(SLICES*c),:,:,3] = cv2.resize(t2[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))                \n",
    "                \n",
    "                y[j +SLICES*c,:,:] = cv2.resize(seg[:,:,j+SLICES_START], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        if DATA_AUG: X, y = AugmentData(X, y)\n",
    "\n",
    "        X = X.reshape(1,SLICES,IMG_SIZE,IMG_SIZE, CHANNELS)\n",
    "        y = y.reshape(1,SLICES,IMG_SIZE,IMG_SIZE)\n",
    "        # Generate masks\n",
    "        #y[y==4] = 3;\n",
    "        y = tf.one_hot(y, 4);\n",
    "\n",
    "        # Avoid dividing by zero - return early\n",
    "        if np.max(X) == 0.0:\n",
    "          return np.zeros(X.shape), y\n",
    "\n",
    "        return X/np.max(X), y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids*DATA_AUG_FACTOR) if DATA_AUG else DataGenerator(train_ids) \n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c2)\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2))(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = UpSampling3D(2)(c11)\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = UpSampling3D(2)(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = UpSampling3D(2)(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "model = unet_3d(input_layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test (baseline) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ktyqcuo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">trim-surf-113</strong>: <a href=\"https://wandb.ai/vj-dl/BraTS2021/runs/2ktyqcuo\" target=\"_blank\">https://wandb.ai/vj-dl/BraTS2021/runs/2ktyqcuo</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221203_134359-2ktyqcuo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2ktyqcuo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221203_134701-ggpmfcsb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/vj-dl/BraTS2021/runs/ggpmfcsb\" target=\"_blank\">icy-fire-114</a></strong> to <a href=\"https://wandb.ai/vj-dl/BraTS2021\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 128, 120, 1  0           []                               \n",
      "                                20, 4)]                                                           \n",
      "                                                                                                  \n",
      " conv3d_15 (Conv3D)             (None, 128, 120, 12  872         ['input_2[0][0]']                \n",
      "                                0, 8)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 128, 120, 12  32         ['conv3d_15[0][0]']              \n",
      " ormalization)                  0, 8)                                                             \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_14[0][0]'] \n",
      "                                0, 8)                                                             \n",
      "                                                                                                  \n",
      " conv3d_16 (Conv3D)             (None, 128, 120, 12  3472        ['activation_15[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 128, 120, 12  64         ['conv3d_16[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_15[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " max_pooling3d_3 (MaxPooling3D)  (None, 64, 60, 60,   0          ['activation_16[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_17 (Conv3D)             (None, 64, 60, 60,   6928        ['max_pooling3d_3[0][0]']        \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 64, 60, 60,   64         ['conv3d_17[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_16[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_18 (Conv3D)             (None, 64, 60, 60,   13856       ['activation_17[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 64, 60, 60,   128        ['conv3d_18[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_17[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_4 (MaxPooling3D)  (None, 32, 30, 30,   0          ['activation_18[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_19 (Conv3D)             (None, 32, 30, 30,   27680       ['max_pooling3d_4[0][0]']        \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 30, 30,   128        ['conv3d_19[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_18[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_20 (Conv3D)             (None, 32, 30, 30,   55360       ['activation_19[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 30, 30,   256        ['conv3d_20[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_19[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_5 (MaxPooling3D)  (None, 16, 15, 15,   0          ['activation_20[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_21 (Conv3D)             (None, 16, 15, 15,   110656      ['max_pooling3d_5[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 15, 15,   256        ['conv3d_21[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 15, 15,   0           ['batch_normalization_20[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_22 (Conv3D)             (None, 16, 15, 15,   221312      ['activation_21[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 15, 15,   512        ['conv3d_22[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 15, 15,   0           ['batch_normalization_21[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " up_sampling3d_3 (UpSampling3D)  (None, 32, 30, 30,   0          ['activation_22[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 32, 30, 30,   0           ['activation_20[0][0]',          \n",
      "                                192)                              'up_sampling3d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_23 (Conv3D)             (None, 32, 30, 30,   331840      ['concatenate_3[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 32, 30, 30,   256        ['conv3d_23[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_22[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_24 (Conv3D)             (None, 32, 30, 30,   110656      ['activation_23[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 32, 30, 30,   256        ['conv3d_24[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_23[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " up_sampling3d_4 (UpSampling3D)  (None, 64, 60, 60,   0          ['activation_24[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 60, 60,   0           ['activation_18[0][0]',          \n",
      "                                96)                               'up_sampling3d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_25 (Conv3D)             (None, 64, 60, 60,   82976       ['concatenate_4[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 64, 60, 60,   128        ['conv3d_25[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_24[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_26 (Conv3D)             (None, 64, 60, 60,   27680       ['activation_25[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 64, 60, 60,   128        ['conv3d_26[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_25[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " up_sampling3d_5 (UpSampling3D)  (None, 128, 120, 12  0          ['activation_26[0][0]']          \n",
      "                                0, 32)                                                            \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128, 120, 12  0           ['activation_16[0][0]',          \n",
      "                                0, 48)                            'up_sampling3d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_27 (Conv3D)             (None, 128, 120, 12  20752       ['concatenate_5[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 128, 120, 12  64         ['conv3d_27[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_26[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_28 (Conv3D)             (None, 128, 120, 12  6928        ['activation_27[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 128, 120, 12  64         ['conv3d_28[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_27[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_29 (Conv3D)             (None, 128, 120, 12  68          ['activation_28[0][0]']          \n",
      "                                0, 4)                                                             \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 128, 120, 12  0           ['conv3d_29[0][0]']              \n",
      "                                0, 4)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,023,372\n",
      "Trainable params: 1,022,204\n",
      "Non-trainable params: 1,168\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      " 23/800 [..............................] - ETA: 7:16 - loss: 0.7545 - accuracy: 0.8494 - mean_io_u_1: 0.3753 - dice_coef: 0.2178 - precision: 0.9435 - sensitivity: 0.5164 - specificity: 0.9913 - dice_coef_necrotic: 0.0254 - dice_coef_edema: 0.0537 - dice_coef_enhancing: 0.0055 - dice_coef_healthy: 0.7867"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate\u001b[39m=\u001b[39mLR), loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMeanIoU(num_classes\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n\u001b[1;32m     15\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[0;32m---> 16\u001b[0m model\u001b[39m.\u001b[39;49mfit(training_generator, epochs\u001b[39m=\u001b[39;49mEPOCHS, validation_data\u001b[39m=\u001b[39;49mvalid_generator, callbacks\u001b[39m=\u001b[39;49m[WandbCallback()])\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m SAVE_MODEL:\n\u001b[1;32m     18\u001b[0m   model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mbaseline_model.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = False # Whether to save the model after training\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=LR), loss=\"categorical_crossentropy\", metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "model.summary()\n",
    "model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[WandbCallback()])\n",
    "if SAVE_MODEL:\n",
    "  model.save(\"baseline_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reconstruct model and test it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/200 [..............................] - ETA: 1:34 - loss: 0.0618 - accuracy: 0.9759 - mean_io_u_6: 0.3752 - dice_coef: 0.4240 - precision: 0.9807 - sensitivity: 0.9730 - specificity: 0.9937 - dice_coef_necrotic: 0.2309 - dice_coef_edema: 0.3966 - dice_coef_enhancing: 0.0773 - dice_coef_healthy: 0.9914"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m reconstructed_model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39mbaseline_model.h5\u001b[39m\u001b[39m\"\u001b[39m, custom_objects\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdice_coef\u001b[39m\u001b[39m\"\u001b[39m:dice_coef, \n\u001b[1;32m      2\u001b[0m                                                                                 \u001b[39m\"\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m\"\u001b[39m:precision, \n\u001b[1;32m      3\u001b[0m                                                                                 \u001b[39m\"\u001b[39m\u001b[39msensitivity\u001b[39m\u001b[39m\"\u001b[39m:sensitivity, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                                 \u001b[39m\"\u001b[39m\u001b[39mdice_coef_enhancing\u001b[39m\u001b[39m\"\u001b[39m:dice_coef_enhancing,\n\u001b[1;32m      8\u001b[0m                                                                                 \u001b[39m\"\u001b[39m\u001b[39mdice_coef_healthy\u001b[39m\u001b[39m\"\u001b[39m: dice_coef_healthy})\n\u001b[0;32m----> 9\u001b[0m reconstructed_model\u001b[39m.\u001b[39;49mevaluate(test_generator)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/engine/training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1943\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1944\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   1945\u001b[0m ):\n\u001b[1;32m   1946\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1947\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   1948\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1949\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reconstructed_model = keras.models.load_model(\"baseline_model.h5\", custom_objects={\"dice_coef\":dice_coef, \n",
    "                                                                                \"precision\":precision, \n",
    "                                                                                \"sensitivity\":sensitivity, \n",
    "                                                                                \"specificity\":specificity,\n",
    "                                                                                \"dice_coef_necrotic\":dice_coef_necrotic, \n",
    "                                                                                \"dice_coef_edema\":dice_coef_edema, \n",
    "                                                                                \"dice_coef_enhancing\":dice_coef_enhancing,\n",
    "                                                                                \"dice_coef_healthy\": dice_coef_healthy})\n",
    "reconstructed_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Callbacks for improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,\n",
    "                               patience=2, verbose=1, mode='auto'),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improved model definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 120, 1  0           []                               \n",
      "                                20, 4)]                                                           \n",
      "                                                                                                  \n",
      " conv3d_30 (Conv3D)             (None, 128, 120, 12  872         ['input_3[0][0]']                \n",
      "                                0, 8)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 128, 120, 12  32         ['conv3d_30[0][0]']              \n",
      " ormalization)                  0, 8)                                                             \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_28[0][0]'] \n",
      "                                0, 8)                                                             \n",
      "                                                                                                  \n",
      " conv3d_31 (Conv3D)             (None, 128, 120, 12  3472        ['activation_30[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 128, 120, 12  64         ['conv3d_31[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_29[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_32 (Conv3D)             (None, 64, 60, 60,   6928        ['activation_31[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_33 (Conv3D)             (None, 64, 60, 60,   6928        ['conv3d_32[0][0]']              \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 64, 60, 60,   64         ['conv3d_33[0][0]']              \n",
      " ormalization)                  16)                                                               \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_30[0][0]'] \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_34 (Conv3D)             (None, 64, 60, 60,   13856       ['activation_32[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 64, 60, 60,   128        ['conv3d_34[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_31[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_35 (Conv3D)             (None, 32, 30, 30,   27680       ['activation_33[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_36 (Conv3D)             (None, 32, 30, 30,   27680       ['conv3d_35[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 32, 30, 30,   128        ['conv3d_36[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_32[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_37 (Conv3D)             (None, 32, 30, 30,   55360       ['activation_34[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 32, 30, 30,   256        ['conv3d_37[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_33[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_38 (Conv3D)             (None, 16, 15, 15,   110656      ['activation_35[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_39 (Conv3D)             (None, 16, 15, 15,   110656      ['conv3d_38[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 16, 15, 15,   256        ['conv3d_39[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 16, 15, 15,   0           ['batch_normalization_34[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_40 (Conv3D)             (None, 16, 15, 15,   221312      ['activation_36[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 16, 15, 15,   512        ['conv3d_40[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 16, 15, 15,   0           ['batch_normalization_35[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose (Conv3DTransp  (None, 32, 30, 30,   131200     ['activation_37[0][0]']          \n",
      " ose)                           128)                                                              \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 32, 30, 30,   0           ['activation_35[0][0]',          \n",
      "                                192)                              'conv3d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " conv3d_41 (Conv3D)             (None, 32, 30, 30,   331840      ['concatenate_6[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 32, 30, 30,   256        ['conv3d_41[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_36[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_42 (Conv3D)             (None, 32, 30, 30,   110656      ['activation_38[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 32, 30, 30,   256        ['conv3d_42[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 32, 30, 30,   0           ['batch_normalization_37[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_1 (Conv3DTran  (None, 64, 60, 60,   32832      ['activation_39[0][0]']          \n",
      " spose)                         64)                                                               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 64, 60, 60,   0           ['activation_33[0][0]',          \n",
      "                                96)                               'conv3d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_43 (Conv3D)             (None, 64, 60, 60,   82976       ['concatenate_7[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 64, 60, 60,   128        ['conv3d_43[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_38[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_44 (Conv3D)             (None, 64, 60, 60,   27680       ['activation_40[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 64, 60, 60,   128        ['conv3d_44[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 64, 60, 60,   0           ['batch_normalization_39[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_2 (Conv3DTran  (None, 128, 120, 12  8224       ['activation_41[0][0]']          \n",
      " spose)                         0, 32)                                                            \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 128, 120, 12  0           ['activation_31[0][0]',          \n",
      "                                0, 48)                            'conv3d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_45 (Conv3D)             (None, 128, 120, 12  20752       ['concatenate_8[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 128, 120, 12  64         ['conv3d_45[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_40[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_46 (Conv3D)             (None, 128, 120, 12  6928        ['activation_42[0][0]']          \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 128, 120, 12  64         ['conv3d_46[0][0]']              \n",
      " ormalization)                  0, 16)                                                            \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 128, 120, 12  0           ['batch_normalization_41[0][0]'] \n",
      "                                0, 16)                                                            \n",
      "                                                                                                  \n",
      " conv3d_47 (Conv3D)             (None, 128, 120, 12  68          ['activation_43[0][0]']          \n",
      "                                0, 4)                                                             \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 128, 120, 12  0           ['conv3d_47[0][0]']              \n",
      "                                0, 4)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,340,892\n",
      "Trainable params: 1,339,724\n",
      "Non-trainable params: 1,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def unet_3d_conv(layer, filters):\n",
    "    layer = Conv3D(filters, kernel_size=(3,3,3), strides=(1,1,1), padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def unet_3d(input_img):\n",
    "    c1 = unet_3d_conv(input_img, 8)\n",
    "    c2 = unet_3d_conv(c1, 16)\n",
    "    \n",
    "    c3 = Conv3D(16, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c2) # Use convolution instead of max pool\n",
    "    \n",
    "\n",
    "    c4 = unet_3d_conv(c3, 16)\n",
    "    c5 = unet_3d_conv(c4, 32)\n",
    "    c6 = Conv3D(32, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c5)\n",
    "\n",
    "    c7 = unet_3d_conv(c6, 32)\n",
    "    c8 = unet_3d_conv(c7, 64)\n",
    "    c9 = Conv3D(64, kernel_size=(3,3,3), strides=(2,2,2), padding='same')(c8)\n",
    "\n",
    "    c10 = unet_3d_conv(c9, 64)\n",
    "    c11 = unet_3d_conv(c10, 128)\n",
    "    c12 = Conv3DTranspose(128, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c11) # Use Transpose instead of UpSampling, kernel size should be divisble by stride\n",
    "    #c12 = UpSampling3D(2)(c11)\n",
    "\n",
    "    c13 = concatenate([c8, c12])\n",
    "    c14 = unet_3d_conv(c13, 64)\n",
    "    c15 = unet_3d_conv(c14, 64)\n",
    "    c16 = Conv3DTranspose(64, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c15)\n",
    "    #c16 = UpSampling3D(2)(c15)\n",
    "\n",
    "    c17 = concatenate([c5, c16])\n",
    "    c18 = unet_3d_conv(c17, 32)\n",
    "    c19 = unet_3d_conv(c18, 32)\n",
    "    c20 = Conv3DTranspose(32, kernel_size=(2,2,2), strides=(2,2,2), padding='same')(c19)\n",
    "    #c20 = UpSampling3D(2)(c19)\n",
    "\n",
    "    c21 = concatenate([c2, c20])\n",
    "    c22 = unet_3d_conv(c21, 16)\n",
    "    c23 = unet_3d_conv(c22, 16)\n",
    "    c24 = Conv3D(4, kernel_size=(1,1,1), strides=(1,1,1), padding='same')(c23)\n",
    "    c25 = Activation('softmax')(c24)\n",
    "\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=c25)\n",
    "    return model \n",
    "\n",
    "\n",
    "input_layer = Input((SLICES, IMG_SIZE, IMG_SIZE, CHANNELS))\n",
    "improved_model = unet_3d(input_layer) \n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and test improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ggpmfcsb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">icy-fire-114</strong>: <a href=\"https://wandb.ai/vj-dl/BraTS2021/runs/ggpmfcsb\" target=\"_blank\">https://wandb.ai/vj-dl/BraTS2021/runs/ggpmfcsb</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221203_134701-ggpmfcsb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ggpmfcsb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/viktorsalling/Documents/Repositories/BraTS2021/wandb/run-20221203_134816-2r6o0kbu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/vj-dl/BraTS2021/runs/2r6o0kbu\" target=\"_blank\">smart-water-115</a></strong> to <a href=\"https://wandb.ai/vj-dl/BraTS2021\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 50/800 [>.............................] - ETA: 9:02 - loss: 0.6162 - accuracy: 0.8733 - mean_io_u_2: 0.3753 - dice_coef: 0.1926 - precision: 0.7697 - sensitivity: 0.2067 - specificity: 0.9845 - dice_coef_necrotic: 0.0506 - dice_coef_edema: 0.0708 - dice_coef_enhancing: 0.0018 - dice_coef_healthy: 0.6470"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m wandb\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m: LR,\n\u001b[1;32m      8\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m: EPOCHS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[39m\"\u001b[39m\u001b[39mslices\u001b[39m\u001b[39m\"\u001b[39m: SLICES\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m improved_model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mNadam(learning_rate\u001b[39m=\u001b[39mLR), loss\u001b[39m=\u001b[39mfocal_tversky_loss, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mMeanIoU(num_classes\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n\u001b[0;32m---> 15\u001b[0m improved_model\u001b[39m.\u001b[39;49mfit(training_generator, epochs\u001b[39m=\u001b[39;49mEPOCHS, validation_data\u001b[39m=\u001b[39;49mvalid_generator, callbacks\u001b[39m=\u001b[39;49m[callbacks, WandbCallback()])\n\u001b[1;32m     16\u001b[0m \u001b[39mif\u001b[39;00m SAVE_MODEL:\n\u001b[1;32m     17\u001b[0m   improved_model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mimproved_model.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/wandb/integration/keras/keras.py:174\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[1;32m    173\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[0;32m--> 174\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/engine/training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \n\u001b[1;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 20\n",
    "SAVE_MODEL = False # Whether to save the model after training\n",
    "\n",
    "wandb.init(project=\"BraTS2021\", entity=\"vj-dl\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": LR,\n",
    "  \"epochs\": EPOCHS,\n",
    "  \"batch_size\": BATCH_SIZE,\n",
    "  \"img_size\": IMG_SIZE, \n",
    "  \"slices\": SLICES\n",
    "}\n",
    "\n",
    "improved_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=LR), loss=focal_tversky_loss, metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing, dice_coef_healthy])\n",
    "improved_model.fit(training_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[callbacks, WandbCallback()])\n",
    "if SAVE_MODEL:\n",
    "  improved_model.save(\"improved_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate improved model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First 0 is just an index of a 3D scan\n",
    "# Next 0 is X in tuple X, y\n",
    "# Next 0 is from the batch. We only have one, so we pick the first.\n",
    "img1 = training_generator.__getitem__(0)[0][0]\n",
    "\n",
    "# Get the ground truth of the training image above (i.e. y from tuple (X, y))\n",
    "img2 = training_generator.__getitem__(0)[1][0]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "# [70,:,:,0] is slice 70. 0 is the FLAIR channel.\n",
    "plt.imshow(img1[70,:,:,0])\n",
    "plt.show()\n",
    "\n",
    "# Same slice as above, 1 is the necrotic tumor core\n",
    "plt.imshow(img2[70, :, :, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions? Maybe we should do an example (or a few) where we use the trained model to predict segmentation masks on data we have not trained on (i.e. the two brain scans that were included in the data set but not in the training-data file**\n",
    "\n",
    "**Something like this:** https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/ **(scroll down to \"predictions\")**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4270e3f338dc97884e39dfa435881d633bb85d0979a79226f74580c90b39f6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
